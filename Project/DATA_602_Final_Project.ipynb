{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "8192e7fe",
      "metadata": {
        "id": "8192e7fe"
      },
      "source": [
        "# Classification "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ca8b9d67",
      "metadata": {
        "id": "ca8b9d67"
      },
      "source": [
        "# Importing Libraries"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2c73a2a2",
      "metadata": {
        "id": "2c73a2a2"
      },
      "source": [
        "All the neccesary Python libraries are imported"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f10e523f",
      "metadata": {
        "id": "f10e523f"
      },
      "outputs": [],
      "source": [
        "#Importing Libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from scipy.stats import pearsonr\n",
        "from scipy.stats import kendalltau\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn import datasets, linear_model, metrics\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import plot_confusion_matrix\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "from sklearn.model_selection import cross_val_predict\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV, RepeatedStratifiedKFold\n",
        "from sklearn import svm\n",
        "from sklearn import metrics\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9b240911",
      "metadata": {
        "id": "9b240911"
      },
      "source": [
        "# Loading Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4e04b0a4",
      "metadata": {
        "id": "4e04b0a4"
      },
      "source": [
        "The Diabetes Dataset which is in the form of a csv file is loaded into 'df' as a Dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "671ffbcb",
      "metadata": {
        "id": "671ffbcb"
      },
      "outputs": [],
      "source": [
        "#Reading the dataset\n",
        "df=pd.read_csv('https://raw.githubusercontent.com/SravaniRVS/DATA602/main/Project/Dataset.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "51134a91",
      "metadata": {
        "id": "51134a91"
      },
      "source": [
        "Top 5 rows of the Dataframe are displayed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6f6e8cc2",
      "metadata": {
        "id": "6f6e8cc2"
      },
      "outputs": [],
      "source": [
        "#Displaying top 5 rows in the dataset\n",
        "df.head(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d9775e1e",
      "metadata": {
        "id": "d9775e1e"
      },
      "source": [
        "# Exploratory Data Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c0274f09",
      "metadata": {
        "id": "c0274f09"
      },
      "source": [
        "Gender wise distribution of class - We can see that there is some anomaly in the data distribution with duplicate values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c079d45e",
      "metadata": {
        "id": "c079d45e"
      },
      "outputs": [],
      "source": [
        "#Output Classes Frequency plot\n",
        "df_gb = df.groupby(['Gender','CLASS']).size().unstack(level=1)\n",
        "df_gb.plot(kind = 'bar')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8944d4b1",
      "metadata": {
        "id": "8944d4b1"
      },
      "source": [
        "Check for the count of null values in the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5ee0d664",
      "metadata": {
        "id": "5ee0d664"
      },
      "outputs": [],
      "source": [
        "#Check for missing values in dataset\n",
        "df.isna().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "DAjN_U6wq6Ph",
      "metadata": {
        "id": "DAjN_U6wq6Ph"
      },
      "outputs": [],
      "source": [
        "df.info() #Information about the dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3c3185d2",
      "metadata": {
        "id": "3c3185d2"
      },
      "source": [
        "Displayig the data balance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dc91fb3a",
      "metadata": {
        "id": "dc91fb3a"
      },
      "outputs": [],
      "source": [
        "data = df['CLASS'].value_counts().to_dict()\n",
        "plt.figure(figsize=(7,7))\n",
        "plt.pie(data.values(), labels = ['Y', 'N', 'P' ,'Y' ,'N'], \n",
        "        wedgeprops={'edgecolor': 'black'},\n",
        "        colors = ['#008fd5', '#fc4f30'],\n",
        "        autopct='%.0f%%', shadow=True)\n",
        "plt.title(\"CLASS\", fontsize=25)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a4084e3b",
      "metadata": {
        "id": "a4084e3b"
      },
      "outputs": [],
      "source": [
        "df['Gender'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b1e5ecae",
      "metadata": {
        "id": "b1e5ecae"
      },
      "outputs": [],
      "source": [
        "data1 = df['Gender'].value_counts().to_dict()\n",
        "plt.figure(figsize=(7,7))\n",
        "plt.pie(data1.values(), labels = ['M', 'F', 'f'], \n",
        "        wedgeprops={'edgecolor': 'black'},\n",
        "        colors = ['#008fd5', '#fc4f30'],\n",
        "        autopct='%.0f%%', shadow=True)\n",
        "plt.title(\"Gender\", fontsize=25)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bcb87b7d",
      "metadata": {
        "id": "bcb87b7d"
      },
      "source": [
        "This clearly shows that this data is very imbalanced data"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0a59bb2e",
      "metadata": {
        "id": "0a59bb2e"
      },
      "source": [
        "Displaying a pairplot to find out the correlation between the various features of the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "40a6f8bf",
      "metadata": {
        "id": "40a6f8bf"
      },
      "outputs": [],
      "source": [
        "#Displaying pairplot that shows relationship among any two variables\n",
        "sns.pairplot(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d8e8f97b",
      "metadata": {
        "id": "d8e8f97b"
      },
      "source": [
        "Correlation Heatmap Plot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b538ee19",
      "metadata": {
        "id": "b538ee19"
      },
      "outputs": [],
      "source": [
        "#Displaying Correlation heatmap which shows the extent of correlation between predictors\n",
        "\n",
        "plt.figure(figsize=(10,6))\n",
        "plot = sns.heatmap(df.corr().round(2), cmap=\"YlGnBu\", annot=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3e47WUidglkv",
      "metadata": {
        "id": "3e47WUidglkv"
      },
      "outputs": [],
      "source": [
        "df.hist(figsize=(12,12))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f1bdbbf3",
      "metadata": {
        "id": "f1bdbbf3"
      },
      "source": [
        "Calculating number of unique values to understand the significance of that column"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6ff9744f",
      "metadata": {
        "id": "6ff9744f"
      },
      "outputs": [],
      "source": [
        "#Number of unique values in ID\n",
        "df.ID.unique().size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fbca732b",
      "metadata": {
        "id": "fbca732b"
      },
      "outputs": [],
      "source": [
        "#Number of unique values in No_Pation\n",
        "df.No_Pation.unique().size"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f1610656",
      "metadata": {
        "id": "f1610656"
      },
      "source": [
        "Check for redundant data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aeeb9b73",
      "metadata": {
        "id": "aeeb9b73"
      },
      "outputs": [],
      "source": [
        "#Check for the unique values in CLASS\n",
        "df['CLASS'].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d62113a9",
      "metadata": {
        "id": "d62113a9"
      },
      "outputs": [],
      "source": [
        "#Check for the unique values in Gender\n",
        "df['Gender'].unique()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a1f455e1",
      "metadata": {
        "id": "a1f455e1"
      },
      "source": [
        "# Feature Engineering"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "54c6e85d",
      "metadata": {
        "id": "54c6e85d"
      },
      "source": [
        "Replacing duplicate values in CLASS and Gender column"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c3bc9ea4",
      "metadata": {
        "id": "c3bc9ea4"
      },
      "outputs": [],
      "source": [
        "#String maniplulation for CLASS Column\n",
        "df['CLASS'] = df['CLASS'].str.replace(\" \", \"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "53589166",
      "metadata": {
        "id": "53589166"
      },
      "outputs": [],
      "source": [
        "df['Gender'] = df['Gender'].str.replace(\"f\", \"F\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "phKLcNhvQFFT",
      "metadata": {
        "id": "phKLcNhvQFFT"
      },
      "outputs": [],
      "source": [
        "df_gb1 = df.groupby(['Gender','CLASS']).size().unstack(level=1)\n",
        "df_gb1.plot(kind = 'bar')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1f816d0f",
      "metadata": {
        "id": "1f816d0f"
      },
      "source": [
        "Dropping ID and No_Pation as they are irrelevant and unique for all patients"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a35ed423",
      "metadata": {
        "id": "a35ed423"
      },
      "outputs": [],
      "source": [
        "#Drop ID and No_Pation column\n",
        "df.drop(['ID','No_Pation'],axis=1,inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "85b4874c",
      "metadata": {
        "id": "85b4874c"
      },
      "outputs": [],
      "source": [
        "df.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ffnedreWnOsK",
      "metadata": {
        "id": "ffnedreWnOsK"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(18,4))\n",
        "\n",
        "plt.subplot(131)\n",
        "sns.barplot(x= 'CLASS',y='BMI',data = df,estimator = np.mean)\n",
        "plt.title(\"Average BMI levels based on CLASS\", fontweight='bold')\n",
        "\n",
        "plt.subplot(132)\n",
        "sns.barplot(x= 'CLASS',y='Urea',data = df,estimator = np.mean)\n",
        "plt.title(\"Average Urea levels based on CLASS\", fontweight='bold')\n",
        "\n",
        "plt.subplot(133)\n",
        "sns.barplot(x= 'CLASS',y='Cr',data = df,estimator = np.mean)\n",
        "plt.title(\"Average Cr levels based on CLASS\", fontweight='bold')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "27356772",
      "metadata": {
        "id": "27356772"
      },
      "source": [
        "Label Encoding Gender and CLASS columns which have categorical values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bbcb5818",
      "metadata": {
        "id": "bbcb5818"
      },
      "outputs": [],
      "source": [
        "#Label Encoding the Gender and CLASS columns\n",
        "le=LabelEncoder()\n",
        "df['Gender']=le.fit_transform(df['Gender'])\n",
        "df['CLASS']=le.fit_transform(df['CLASS'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b3e30348",
      "metadata": {
        "id": "b3e30348"
      },
      "outputs": [],
      "source": [
        "df.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "_y_imbalance = df['CLASS'].value_counts()/len(df)*100  # % of each class in the dataset\n",
        "\n",
        "_y_imbalance"
      ],
      "metadata": {
        "id": "yuDtVScxHOyi"
      },
      "id": "yuDtVScxHOyi",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dict_y = { '2':int( _y_imbalance[0]),\n",
        "          '0': int(_y_imbalance[1]),\n",
        "          '1': int(_y_imbalance[2]),\n",
        "    \n",
        "}"
      ],
      "metadata": {
        "id": "p-_l90nBKMY5"
      },
      "id": "p-_l90nBKMY5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type_ = list(dict_y.keys())\n",
        "percentage = list(dict_y.values())\n",
        "fig = plt.figure(figsize = (10, 5))\n",
        "# creating the bar plot\n",
        "plt.bar(type_, percentage, color ='maroon',\n",
        "        width = 0.4)\n",
        "plt.xlabel(\"Class\")\n",
        "plt.ylabel(\"%age of each class\")\n",
        "plt.title(\"Value Count of each Class in (% age)\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "zgFHoMoBLEGN"
      },
      "id": "zgFHoMoBLEGN",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- The bar graph shows the imbalance in the dataset. Majority of the values are of class 1 which is around 84%"
      ],
      "metadata": {
        "id": "1Qn7OVP1MMB3"
      },
      "id": "1Qn7OVP1MMB3"
    },
    {
      "cell_type": "code",
      "source": [
        "df.corr()"
      ],
      "metadata": {
        "id": "A6DbBg8DcptV"
      },
      "id": "A6DbBg8DcptV",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "7c27919f",
      "metadata": {
        "id": "7c27919f"
      },
      "source": [
        "Splitting the dataframe into features (X) and labels (y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fd5f1f3d",
      "metadata": {
        "id": "fd5f1f3d"
      },
      "outputs": [],
      "source": [
        "#Splitting dataframe into features (X) and output (y)\n",
        "X=df.iloc[:,0:11]\n",
        "y=df.iloc[:,11]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c54b899e",
      "metadata": {
        "id": "c54b899e"
      },
      "outputs": [],
      "source": [
        "y"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, the data is balance, we have equal percentage of data of every class type."
      ],
      "metadata": {
        "id": "F90ajhgQUK9R"
      },
      "id": "F90ajhgQUK9R"
    },
    {
      "cell_type": "markdown",
      "id": "33f848dc",
      "metadata": {
        "id": "33f848dc"
      },
      "source": [
        "#  Model 1 - Continous Features"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4271a75a",
      "metadata": {
        "id": "4271a75a"
      },
      "source": [
        "Defining the features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d7aeb576",
      "metadata": {
        "id": "d7aeb576"
      },
      "outputs": [],
      "source": [
        "#Defining the dataframe of only continous features\n",
        "X2= X.drop(['Gender'],axis=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "81f57d7a",
      "metadata": {
        "id": "81f57d7a"
      },
      "outputs": [],
      "source": [
        "len(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8fb539f4",
      "metadata": {
        "id": "8fb539f4"
      },
      "outputs": [],
      "source": [
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X2)\n",
        "X_scaled[:3]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2161a30f",
      "metadata": {
        "id": "2161a30f"
      },
      "source": [
        "Splitting the dataset into traning ad test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "989fcee0",
      "metadata": {
        "id": "989fcee0"
      },
      "outputs": [],
      "source": [
        "#Train Test split of the entire dataset for training purpose\n",
        "X_train, X_test, y_train, y_test = train_test_split(X2 ,y , random_state=42,test_size=0.20, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X2"
      ],
      "metadata": {
        "id": "mfiUrc2Hz4qK"
      },
      "id": "mfiUrc2Hz4qK",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y.value_counts()"
      ],
      "metadata": {
        "id": "5Ix9dNyY05Bc"
      },
      "id": "5Ix9dNyY05Bc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "c9b8d459",
      "metadata": {
        "id": "c9b8d459"
      },
      "source": [
        "Fitting the data to Gaussian Naive Bayes Classifier along with model performnace validation using accuracy score, classification report, confusion matrix"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import precision_score,recall_score #precision score"
      ],
      "metadata": {
        "id": "UdrXfXDS1DJP"
      },
      "id": "UdrXfXDS1DJP",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b8daf77f",
      "metadata": {
        "id": "b8daf77f"
      },
      "outputs": [],
      "source": [
        "#Model Instatntiated\n",
        "model1 = GaussianNB()\n",
        "#Data fit to the model\n",
        "model1.fit(X_train, y_train.values)\n",
        "#Model Performance Evaluation\n",
        "y_pred_train = model1.predict(X_train)\n",
        "y_pred_test = model1.predict(X_test)\n",
        "#print(\"Gaussian Naive Bayes model accuracy with continous features:\", metrics.accuracy_score(y_test, y_pred)*100)\n",
        "\n",
        "#Displaying Confusion Matrix \n",
        "\n",
        "cm_train = confusion_matrix(y_train,y_pred_train )\n",
        "cm_test = confusion_matrix(y_test,y_pred_test )\n",
        "\n",
        "fig, axes = plt.subplots(1, 2,figsize=(15, 5), sharey=True)\n",
        "sns.heatmap(cm_train,annot=True,ax=axes[0])\n",
        "sns.heatmap(cm_test,annot=True,ax=axes[1])\n",
        "axes[0].set_title(\"Confusion Matrix on Train Data\")\n",
        "axes[1].set_title(\"Confusion Matrix on Test Data\")\n",
        "axes[0].set_xlabel('Actual')\n",
        "axes[0].set_ylabel('Predict')\n",
        "axes[1].set_xlabel('Actual')\n",
        "axes[1].set_ylabel('Predict')\n",
        "plt.show()\n",
        "\n",
        "precision_train=precision_score(y_train,y_pred_train,zero_division='warn',average='micro')\n",
        "\n",
        "# model precision for X_train and X_test \n",
        "print( \"Precision on Train Data : \", str(int(precision_train*100)) +'%' )\n",
        "\n",
        "precision_test=precision_score(y_test,y_pred_test,zero_division='warn',average='micro')\n",
        "\n",
        "print( \"Precision on Test Data : \", str(int(precision_test*100)) +'%' ,)\n",
        "\n",
        "recall_train=recall_score(y_train,y_pred_train,zero_division='warn',average='micro')\n",
        "\n",
        "# model recall for X_train and X_test \n",
        "\n",
        "print( \"Recall on Train Data : \", str(int(recall_train*100)) +'%' )\n",
        "\n",
        "recall_test=recall_score(y_test,y_pred_test,zero_division='warn',average='micro')\n",
        "\n",
        "print( \"Recall on Test Data : \", str(int(recall_test*100)) +'%' ,)\n",
        "\n",
        "# model F-1 score for X_train and X_test\n",
        "F1_score_train =f1_score(y_train, y_pred_train,zero_division='warn',average='micro')\n",
        "\n",
        "print( \"F1 on Train Data : \", str(int(F1_score_train*100)) +'%' )\n",
        "\n",
        "F1_score_test =f1_score(y_test, y_pred_test,zero_division='warn',average='micro')\n",
        "\n",
        "print( \"F1 on Test Data : \", str(int(F1_score_test*100)) +'%' )\n",
        "\n",
        "#Displaying Classification Report\n",
        "\n",
        "print(\"\")\n",
        "print(\"Classification Report for Test Data\")\n",
        "print(\"\")\n",
        "print(classification_report(y_train, y_pred_train))\n",
        "print(\"\")\n",
        "print(\"Classification Report for Test Data\")\n",
        "print(\"\")\n",
        "print(classification_report(y_test, y_pred_test))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "700b88b4",
      "metadata": {
        "id": "700b88b4"
      },
      "source": [
        "Fitting the data to Logistic Regression Classifier alongwith model performnace validation using accuracy score, classification report, confusion matrix and R2 score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3fb2e709",
      "metadata": {
        "id": "3fb2e709"
      },
      "outputs": [],
      "source": [
        "#Model Instatntiated\n",
        "model2 = LogisticRegression(multi_class='multinomial')\n",
        "\n",
        "#Data fit to the model\n",
        "model2.fit(X_train, y_train)\n",
        "#Model Performance Evaluation\n",
        "y_pred_train = model2.predict(X_train)\n",
        "y_pred_test = model2.predict(X_test)\n",
        "#print(\"Gaussian Naive Bayes model accuracy with continous features:\", metrics.accuracy_score(y_test, y_pred)*100)\n",
        "\n",
        "#Displaying Confusion Matrix \n",
        "\n",
        "cm_train = confusion_matrix(y_train,y_pred_train )\n",
        "cm_test = confusion_matrix(y_test,y_pred_test )\n",
        "\n",
        "fig, axes = plt.subplots(1, 2,figsize=(15, 5), sharey=True)\n",
        "sns.heatmap(cm_train,annot=True,ax=axes[0])\n",
        "sns.heatmap(cm_test,annot=True,ax=axes[1])\n",
        "axes[0].set_title(\"Confusion Matrix on Train Data\")\n",
        "axes[1].set_title(\"Confusion Matrix on Test Data\")\n",
        "axes[0].set_xlabel('Actual')\n",
        "axes[0].set_ylabel('Predict')\n",
        "axes[1].set_xlabel('Actual')\n",
        "axes[1].set_ylabel('Predict')\n",
        "plt.show()\n",
        "\n",
        "precision_train=precision_score(y_train,y_pred_train,zero_division='warn',average='micro')\n",
        "\n",
        "# model precision for X_train and X_test \n",
        "print( \"Precision on Train Data : \", str(int(precision_train*100)) +'%' )\n",
        "\n",
        "precision_test=precision_score(y_test,y_pred_test,zero_division='warn',average='micro')\n",
        "\n",
        "print( \"Precision on Test Data : \", str(int(precision_test*100)) +'%' ,)\n",
        "\n",
        "recall_train=recall_score(y_train,y_pred_train,zero_division='warn',average='micro')\n",
        "\n",
        "# model recall for X_train and X_test \n",
        "\n",
        "print( \"Recall on Train Data : \", str(int(recall_train*100)) +'%' )\n",
        "\n",
        "recall_test=recall_score(y_test,y_pred_test,zero_division='warn',average='micro')\n",
        "\n",
        "print( \"Recall on Test Data : \", str(int(recall_test*100)) +'%' ,)\n",
        "\n",
        "# model F-1 score for X_train and X_test\n",
        "F1_score_train =f1_score(y_train, y_pred_train,zero_division='warn',average='micro')\n",
        "\n",
        "print( \"F1 on Train Data : \", str(int(F1_score_train*100)) +'%' )\n",
        "\n",
        "F1_score_test =f1_score(y_test, y_pred_test,zero_division='warn',average='micro')\n",
        "\n",
        "print( \"F1 on Test Data : \", str(int(F1_score_test*100)) +'%' )\n",
        "\n",
        "#Displaying Classification Report\n",
        "\n",
        "print(\"\")\n",
        "print(\"Classification Report for Test Data\")\n",
        "print(\"\")\n",
        "print(classification_report(y_train, y_pred_train))\n",
        "print(\"\")\n",
        "print(\"Classification Report for Test Data\")\n",
        "print(\"\")\n",
        "print(classification_report(y_test, y_pred_test))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lets use scaled features"
      ],
      "metadata": {
        "id": "MKrz9JI66h_w"
      },
      "id": "MKrz9JI66h_w"
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#Train Test split of the entire dataset for training purpose\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled ,y , random_state=42,test_size=0.20, shuffle=True)\n",
        "#Model Instatntiated\n",
        "model2 = LogisticRegression(multi_class='multinomial')\n",
        "\n",
        "#Data fit to the model\n",
        "model2.fit(X_train, y_train)\n",
        "#Model Performance Evaluation\n",
        "y_pred_train = model2.predict(X_train)\n",
        "y_pred_test = model2.predict(X_test)\n",
        "#print(\"Gaussian Naive Bayes model accuracy with continous features:\", metrics.accuracy_score(y_test, y_pred)*100)\n",
        "\n",
        "#Displaying Confusion Matrix \n",
        "\n",
        "cm_train = confusion_matrix(y_train,y_pred_train )\n",
        "cm_test = confusion_matrix(y_test,y_pred_test )\n",
        "\n",
        "fig, axes = plt.subplots(1, 2,figsize=(15, 5), sharey=True)\n",
        "sns.heatmap(cm_train,annot=True,ax=axes[0])\n",
        "sns.heatmap(cm_test,annot=True,ax=axes[1])\n",
        "axes[0].set_title(\"Confusion Matrix on Train Data\")\n",
        "axes[1].set_title(\"Confusion Matrix on Test Data\")\n",
        "axes[0].set_xlabel('Actual')\n",
        "axes[0].set_ylabel('Predict')\n",
        "axes[1].set_xlabel('Actual')\n",
        "axes[1].set_ylabel('Predict')\n",
        "plt.show()\n",
        "\n",
        "precision_train=precision_score(y_train,y_pred_train,zero_division='warn',average='micro')\n",
        "\n",
        "# model precision for X_train and X_test \n",
        "print( \"Precision on Train Data : \", str(int(precision_train*100)) +'%' )\n",
        "\n",
        "precision_test=precision_score(y_test,y_pred_test,zero_division='warn',average='micro')\n",
        "\n",
        "print( \"Precision on Test Data : \", str(int(precision_test*100)) +'%' ,)\n",
        "\n",
        "recall_train=recall_score(y_train,y_pred_train,zero_division='warn',average='micro')\n",
        "\n",
        "# model recall for X_train and X_test \n",
        "\n",
        "print( \"Recall on Train Data : \", str(int(recall_train*100)) +'%' )\n",
        "\n",
        "recall_test=recall_score(y_test,y_pred_test,zero_division='warn',average='micro')\n",
        "\n",
        "print( \"Recall on Test Data : \", str(int(recall_test*100)) +'%' ,)\n",
        "\n",
        "# model F-1 score for X_train and X_test\n",
        "F1_score_train =f1_score(y_train, y_pred_train,zero_division='warn',average='micro')\n",
        "\n",
        "print( \"F1 on Train Data : \", str(int(F1_score_train*100)) +'%' )\n",
        "\n",
        "F1_score_test =f1_score(y_test, y_pred_test,zero_division='warn',average='micro')\n",
        "\n",
        "print( \"F1 on Test Data : \", str(int(F1_score_test*100)) +'%' )\n",
        "\n",
        "#Displaying Classification Report\n",
        "\n",
        "print(\"\")\n",
        "print(\"Classification Report for Test Data\")\n",
        "print(\"\")\n",
        "print(classification_report(y_train, y_pred_train))\n",
        "print(\"\")\n",
        "print(\"Classification Report for Test Data\")\n",
        "print(\"\")\n",
        "print(classification_report(y_test, y_pred_test))\n",
        "\n"
      ],
      "metadata": {
        "id": "sC5Htm4A6BxE"
      },
      "id": "sC5Htm4A6BxE",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "2f503341",
      "metadata": {
        "id": "2f503341"
      },
      "source": [
        "Fitting the data to Support Vector Machine Classifier alongwith model performnace validation using accuracy score, classification report, confusion matrix and R2 score"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC"
      ],
      "metadata": {
        "id": "VXZXwGAb7eCW"
      },
      "id": "VXZXwGAb7eCW",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2ea3da8c",
      "metadata": {
        "id": "2ea3da8c"
      },
      "outputs": [],
      "source": [
        "\n",
        "#Train Test split of the entire dataset for training purpose\n",
        "X_train, X_test, y_train, y_test = train_test_split(X ,y , random_state=42,test_size=0.20, shuffle=True)\n",
        "#Model Instatntiated\n",
        "model3 = SVC(kernel = 'linear', C = 1)\n",
        "\n",
        "#Data fit to the model\n",
        "model3.fit(X_train, y_train)\n",
        "\n",
        "#Model Performance Evaluation\n",
        "y_pred_train = model3.predict(X_train)\n",
        "y_pred_test = model3.predict(X_test)\n",
        "\n",
        "#Displaying Confusion Matrix \n",
        "\n",
        "cm_train = confusion_matrix(y_train,y_pred_train )\n",
        "cm_test = confusion_matrix(y_test,y_pred_test )\n",
        "\n",
        "fig, axes = plt.subplots(1, 2,figsize=(15, 5), sharey=True)\n",
        "sns.heatmap(cm_train,annot=True,ax=axes[0])\n",
        "sns.heatmap(cm_test,annot=True,ax=axes[1])\n",
        "axes[0].set_title(\"Confusion Matrix on Train Data\")\n",
        "axes[1].set_title(\"Confusion Matrix on Test Data\")\n",
        "axes[0].set_xlabel('Actual')\n",
        "axes[0].set_ylabel('Predict')\n",
        "axes[1].set_xlabel('Actual')\n",
        "axes[1].set_ylabel('Predict')\n",
        "plt.show()\n",
        "\n",
        "precision_train=precision_score(y_train,y_pred_train,zero_division='warn',average='micro')\n",
        "\n",
        "# model precision for X_train and X_test \n",
        "print( \"Precision on Train Data : \", str(int(precision_train*100)) +'%' )\n",
        "\n",
        "precision_test=precision_score(y_test,y_pred_test,zero_division='warn',average='micro')\n",
        "\n",
        "print( \"Precision on Test Data : \", str(int(precision_test*100)) +'%' ,)\n",
        "\n",
        "recall_train=recall_score(y_train,y_pred_train,zero_division='warn',average='micro')\n",
        "\n",
        "# model recall for X_train and X_test \n",
        "\n",
        "print( \"Recall on Train Data : \", str(int(recall_train*100)) +'%' )\n",
        "\n",
        "recall_test=recall_score(y_test,y_pred_test,zero_division='warn',average='micro')\n",
        "\n",
        "print( \"Recall on Test Data : \", str(int(recall_test*100)) +'%' ,)\n",
        "\n",
        "# model F-1 score for X_train and X_test\n",
        "F1_score_train =f1_score(y_train, y_pred_train,zero_division='warn',average='micro')\n",
        "\n",
        "print( \"F1 on Train Data : \", str(int(F1_score_train*100)) +'%' )\n",
        "\n",
        "F1_score_test =f1_score(y_test, y_pred_test,zero_division='warn',average='micro')\n",
        "\n",
        "print( \"F1 on Test Data : \", str(int(F1_score_test*100)) +'%' )\n",
        "\n",
        "#Displaying Classification Report\n",
        "\n",
        "print(\"\")\n",
        "print(\"Classification Report for Test Data\")\n",
        "print(\"\")\n",
        "print(classification_report(y_train, y_pred_train))\n",
        "print(\"\")\n",
        "print(\"Classification Report for Test Data\")\n",
        "print(\"\")\n",
        "print(classification_report(y_test, y_pred_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6a409aed",
      "metadata": {
        "id": "6a409aed"
      },
      "source": [
        "Fitting the data to K Neighbors Classifier with K=3 alongwith model performnace validation using accuracy score, classification report, confusion matrix and R2 score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6a3b226c",
      "metadata": {
        "id": "6a3b226c"
      },
      "outputs": [],
      "source": [
        "\n",
        "#Train Test split of the entire dataset for training purpose\n",
        "X_train, X_test, y_train, y_test = train_test_split(X ,y , random_state=42,test_size=0.20, shuffle=True)\n",
        "#Model Instatntiated\n",
        "model4 = KNeighborsClassifier(n_neighbors=3)\n",
        "\n",
        "#Data fit to the model\n",
        "model4.fit(X_train, y_train)\n",
        "\n",
        "#Model Performance Evaluation\n",
        "y_pred_train = model4.predict(X_train)\n",
        "y_pred_test = model4.predict(X_test)\n",
        "\n",
        "#Displaying Confusion Matrix \n",
        "\n",
        "cm_train = confusion_matrix(y_train,y_pred_train )\n",
        "cm_test = confusion_matrix(y_test,y_pred_test )\n",
        "\n",
        "fig, axes = plt.subplots(1, 2,figsize=(15, 5), sharey=True)\n",
        "sns.heatmap(cm_train,annot=True,ax=axes[0])\n",
        "sns.heatmap(cm_test,annot=True,ax=axes[1])\n",
        "axes[0].set_title(\"Confusion Matrix on Train Data\")\n",
        "axes[1].set_title(\"Confusion Matrix on Test Data\")\n",
        "axes[0].set_xlabel('Actual')\n",
        "axes[0].set_ylabel('Predict')\n",
        "axes[1].set_xlabel('Actual')\n",
        "axes[1].set_ylabel('Predict')\n",
        "plt.show()\n",
        "\n",
        "precision_train=precision_score(y_train,y_pred_train,zero_division='warn',average='micro')\n",
        "\n",
        "# model precision for X_train and X_test \n",
        "print( \"Precision on Train Data : \", str(int(precision_train*100)) +'%' )\n",
        "\n",
        "precision_test=precision_score(y_test,y_pred_test,zero_division='warn',average='micro')\n",
        "\n",
        "print( \"Precision on Test Data : \", str(int(precision_test*100)) +'%' ,)\n",
        "\n",
        "recall_train=recall_score(y_train,y_pred_train,zero_division='warn',average='micro')\n",
        "\n",
        "# model recall for X_train and X_test \n",
        "\n",
        "print( \"Recall on Train Data : \", str(int(recall_train*100)) +'%' )\n",
        "\n",
        "recall_test=recall_score(y_test,y_pred_test,zero_division='warn',average='micro')\n",
        "\n",
        "print( \"Recall on Test Data : \", str(int(recall_test*100)) +'%' ,)\n",
        "\n",
        "# model F-1 score for X_train and X_test\n",
        "F1_score_train =f1_score(y_train, y_pred_train,zero_division='warn',average='micro')\n",
        "\n",
        "print( \"F1 on Train Data : \", str(int(F1_score_train*100)) +'%' )\n",
        "\n",
        "F1_score_test =f1_score(y_test, y_pred_test,zero_division='warn',average='micro')\n",
        "\n",
        "print( \"F1 on Test Data : \", str(int(F1_score_test*100)) +'%' )\n",
        "\n",
        "#Displaying Classification Report\n",
        "\n",
        "print(\"\")\n",
        "print(\"Classification Report for Test Data\")\n",
        "print(\"\")\n",
        "print(classification_report(y_train, y_pred_train))\n",
        "print(\"\")\n",
        "print(\"Classification Report for Test Data\")\n",
        "print(\"\")\n",
        "print(classification_report(y_test, y_pred_test))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# calculating the accuracy of models with different values of k\n",
        "Test_f_1_score = np.zeros(20)\n",
        "for i in range(1,21):\n",
        "    #Train Model and Predict  \n",
        "    knn = KNeighborsClassifier(n_neighbors = i).fit(X_train,y_train)\n",
        "    yhat= knn.predict(X_test)\n",
        "    Test_f_1_score[i-1] = f1_score(y_test, yhat,average='micro')\n",
        "\n",
        "print(Test_f_1_score)"
      ],
      "metadata": {
        "id": "Wbkhf-ea8-k2"
      },
      "id": "Wbkhf-ea8-k2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# calculating the accuracy of models with different values of k\n",
        "Train_f_1_score = np.zeros(20)\n",
        "for i in range(1,21):\n",
        "    #Train Model and Predict  \n",
        "    knn = KNeighborsClassifier(n_neighbors = i).fit(X_train,y_train)\n",
        "    yhat= knn.predict(X_train)\n",
        "    Train_f_1_score[i-1] = f1_score(y_train, yhat,average='micro')\n",
        "\n",
        "print(Train_f_1_score)"
      ],
      "metadata": {
        "id": "aBSnYdo89dFd"
      },
      "id": "aBSnYdo89dFd",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loc = np.arange(1,21,step=1.0)\n",
        "plt.figure(figsize = (10, 6))\n",
        "line1, = plt.plot(range(1,21), Train_f_1_score,label='Train F_1 score')\n",
        "line2, = plt.plot(range(1,21), Test_f_1_score,linestyle = 'dashed',label='Test F_1 score')\n",
        "\n",
        "plt.legend(handles=[line1, line2])\n",
        "plt.xticks(loc)\n",
        "plt.xlabel('Number of Neighbors ')\n",
        "plt.ylabel('F1-Score')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "t5yRcnjY9FnQ"
      },
      "id": "t5yRcnjY9FnQ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "  At K=7 the value of Train F1-score is 0.946 and Train F1-score is 0.945 which is very close and gives the optimal value of K."
      ],
      "metadata": {
        "id": "pEnYRIQW9SHq"
      },
      "id": "pEnYRIQW9SHq"
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#Train Test split of the entire dataset for training purpose\n",
        "X_train, X_test, y_train, y_test = train_test_split(X ,y , random_state=0,test_size=0.20, shuffle=True)\n",
        "#Model Instatntiated\n",
        "model4 = KNeighborsClassifier(n_neighbors=7)\n",
        "\n",
        "#Data fit to the model\n",
        "model4.fit(X_train, y_train)\n",
        "\n",
        "#Model Performance Evaluation\n",
        "y_pred_train = model4.predict(X_train)\n",
        "y_pred_test = model4.predict(X_test)\n",
        "\n",
        "#Displaying Confusion Matrix \n",
        "\n",
        "cm_train = confusion_matrix(y_train,y_pred_train )\n",
        "cm_test = confusion_matrix(y_test,y_pred_test )\n",
        "\n",
        "fig, axes = plt.subplots(1, 2,figsize=(15, 5), sharey=True)\n",
        "sns.heatmap(cm_train,annot=True,ax=axes[0])\n",
        "sns.heatmap(cm_test,annot=True,ax=axes[1])\n",
        "axes[0].set_title(\"Confusion Matrix on Train Data\")\n",
        "axes[1].set_title(\"Confusion Matrix on Test Data\")\n",
        "axes[0].set_xlabel('Actual')\n",
        "axes[0].set_ylabel('Predict')\n",
        "axes[1].set_xlabel('Actual')\n",
        "axes[1].set_ylabel('Predict')\n",
        "plt.show()\n",
        "\n",
        "precision_train=precision_score(y_train,y_pred_train,zero_division='warn',average='micro')\n",
        "\n",
        "# model precision for X_train and X_test \n",
        "print( \"Precision on Train Data : \", str(int(precision_train*100)) +'%' )\n",
        "\n",
        "precision_test=precision_score(y_test,y_pred_test,zero_division='warn',average='micro')\n",
        "\n",
        "print( \"Precision on Test Data : \", str(int(precision_test*100)) +'%' ,)\n",
        "\n",
        "recall_train=recall_score(y_train,y_pred_train,zero_division='warn',average='micro')\n",
        "\n",
        "# model recall for X_train and X_test \n",
        "\n",
        "print( \"Recall on Train Data : \", str(int(recall_train*100)) +'%' )\n",
        "\n",
        "recall_test=recall_score(y_test,y_pred_test,zero_division='warn',average='micro')\n",
        "\n",
        "print( \"Recall on Test Data : \", str(int(recall_test*100)) +'%' ,)\n",
        "\n",
        "# model F-1 score for X_train and X_test\n",
        "F1_score_train =f1_score(y_train, y_pred_train,zero_division='warn',average='micro')\n",
        "\n",
        "print( \"F1 on Train Data : \", str(int(F1_score_train*100)) +'%' )\n",
        "\n",
        "F1_score_test =f1_score(y_test, y_pred_test,zero_division='warn',average='micro')\n",
        "\n",
        "print( \"F1 on Test Data : \", str(int(F1_score_test*100)) +'%' )\n",
        "\n",
        "#Displaying Classification Report\n",
        "\n",
        "print(\"\")\n",
        "print(\"Classification Report for Train Data\")\n",
        "print(\"\")\n",
        "print(classification_report(y_train, y_pred_train))\n",
        "print(\"\")\n",
        "print(\"Classification Report for Test Data\")\n",
        "print(\"\")\n",
        "print(classification_report(y_test, y_pred_test))"
      ],
      "metadata": {
        "id": "TXd5m-plANgF"
      },
      "id": "TXd5m-plANgF",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "cc9f0a5e",
      "metadata": {
        "id": "cc9f0a5e"
      },
      "source": [
        "Fitting the data to Decision Tree Classifier alongwith model performnace validation using accuracy score, classification report, confusion matrix and R2 score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "49573db6",
      "metadata": {
        "id": "49573db6"
      },
      "outputs": [],
      "source": [
        "#Model Instatntiated\n",
        "model5 = DecisionTreeClassifier(random_state=0)\n",
        "\n",
        "#Data fit to the model\n",
        "model5.fit(X_train, y_train)\n",
        "\n",
        "#Model Performance Evaluation\n",
        "y_pred_train = model5.predict(X_train)\n",
        "y_pred_test = model5.predict(X_test)\n",
        "\n",
        "#Displaying Confusion Matrix \n",
        "\n",
        "cm_train = confusion_matrix(y_train,y_pred_train )\n",
        "cm_test = confusion_matrix(y_test,y_pred_test )\n",
        "\n",
        "fig, axes = plt.subplots(1, 2,figsize=(15, 5), sharey=True)\n",
        "sns.heatmap(cm_train,annot=True,ax=axes[0])\n",
        "sns.heatmap(cm_test,annot=True,ax=axes[1])\n",
        "axes[0].set_title(\"Confusion Matrix on Train Data\")\n",
        "axes[1].set_title(\"Confusion Matrix on Test Data\")\n",
        "axes[0].set_xlabel('Actual')\n",
        "axes[0].set_ylabel('Predict')\n",
        "axes[1].set_xlabel('Actual')\n",
        "axes[1].set_ylabel('Predict')\n",
        "plt.show()\n",
        "\n",
        "precision_train=precision_score(y_train,y_pred_train,zero_division='warn',average='micro')\n",
        "\n",
        "# model precision for X_train and X_test \n",
        "print( \"Precision on Train Data : \", str(int(precision_train*100)) +'%' )\n",
        "\n",
        "precision_test=precision_score(y_test,y_pred_test,zero_division='warn',average='micro')\n",
        "\n",
        "print( \"Precision on Test Data : \", str(int(precision_test*100)) +'%' ,)\n",
        "\n",
        "recall_train=recall_score(y_train,y_pred_train,zero_division='warn',average='micro')\n",
        "\n",
        "# model recall for X_train and X_test \n",
        "\n",
        "print( \"Recall on Train Data : \", str(int(recall_train*100)) +'%' )\n",
        "\n",
        "recall_test=recall_score(y_test,y_pred_test,zero_division='warn',average='micro')\n",
        "\n",
        "print( \"Recall on Test Data : \", str(int(recall_test*100)) +'%' ,)\n",
        "\n",
        "# model F-1 score for X_train and X_test\n",
        "F1_score_train =f1_score(y_train, y_pred_train,zero_division='warn',average='micro')\n",
        "\n",
        "print( \"F1 on Train Data : \", str(int(F1_score_train*100)) +'%' )\n",
        "\n",
        "F1_score_test =f1_score(y_test, y_pred_test,zero_division='warn',average='micro')\n",
        "\n",
        "print( \"F1 on Test Data : \", str(int(F1_score_test*100)) +'%' )\n",
        "\n",
        "#Displaying Classification Report\n",
        "\n",
        "print(\"\")\n",
        "print(\"Classification Report for Train Data\")\n",
        "print(\"\")\n",
        "print(classification_report(y_train, y_pred_train))\n",
        "print(\"\")\n",
        "print(\"Classification Report for Test Data\")\n",
        "print(\"\")\n",
        "print(classification_report(y_test, y_pred_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "36816157",
      "metadata": {
        "id": "36816157"
      },
      "source": [
        "Fitting the data to Random Forest Classifier alongwith model performnace validation using accuracy score, classification report, confusion matrix and R2 score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0db1e351",
      "metadata": {
        "id": "0db1e351"
      },
      "outputs": [],
      "source": [
        "#Train Test split of the entire dataset for training purpose\n",
        "X_train, X_test, y_train, y_test = train_test_split(X ,y , random_state=0,test_size=0.20, shuffle=True)\n",
        "#Model Instatntiated\n",
        "model6 = RandomForestClassifier(criterion='entropy',n_estimators=50)\n",
        "model6.fit(X_train, y_train)\n",
        "#Model Performance Evaluation\n",
        "y_pred_train = model6.predict(X_train)\n",
        "y_pred_test = model6.predict(X_test)\n",
        "\n",
        "#Displaying Confusion Matrix \n",
        "\n",
        "cm_train = confusion_matrix(y_train,y_pred_train )\n",
        "cm_test = confusion_matrix(y_test,y_pred_test )\n",
        "\n",
        "fig, axes = plt.subplots(1, 2,figsize=(15, 5), sharey=True)\n",
        "sns.heatmap(cm_train,annot=True,ax=axes[0])\n",
        "sns.heatmap(cm_test,annot=True,ax=axes[1])\n",
        "axes[0].set_title(\"Confusion Matrix on Train Data\")\n",
        "axes[1].set_title(\"Confusion Matrix on Test Data\")\n",
        "axes[0].set_xlabel('Actual')\n",
        "axes[0].set_ylabel('Predict')\n",
        "axes[1].set_xlabel('Actual')\n",
        "axes[1].set_ylabel('Predict')\n",
        "plt.show()\n",
        "\n",
        "precision_train=precision_score(y_train,y_pred_train,zero_division='warn',average='micro')\n",
        "\n",
        "# model precision for X_train and X_test \n",
        "print( \"Precision on Train Data : \", str(int(precision_train*100)) +'%' )\n",
        "\n",
        "precision_test=precision_score(y_test,y_pred_test,zero_division='warn',average='micro')\n",
        "\n",
        "print( \"Precision on Test Data : \", str(int(precision_test*100)) +'%' ,)\n",
        "\n",
        "recall_train=recall_score(y_train,y_pred_train,zero_division='warn',average='micro')\n",
        "\n",
        "# model recall for X_train and X_test \n",
        "\n",
        "print( \"Recall on Train Data : \", str(int(recall_train*100)) +'%' )\n",
        "\n",
        "recall_test=recall_score(y_test,y_pred_test,zero_division='warn',average='micro')\n",
        "\n",
        "print( \"Recall on Test Data : \", str(int(recall_test*100)) +'%' ,)\n",
        "\n",
        "# model F-1 score for X_train and X_test\n",
        "F1_score_train =f1_score(y_train, y_pred_train,zero_division='warn',average='micro')\n",
        "\n",
        "print( \"F1 on Train Data : \", str(int(F1_score_train*100)) +'%' )\n",
        "\n",
        "F1_score_test =f1_score(y_test, y_pred_test,zero_division='warn',average='micro')\n",
        "\n",
        "print( \"F1 on Test Data : \", str(int(F1_score_test*100)) +'%' )\n",
        "\n",
        "#Displaying Classification Report\n",
        "\n",
        "print(\"\")\n",
        "print(\"Classification Report for Train Data\")\n",
        "print(\"\")\n",
        "print(classification_report(y_train, y_pred_train))\n",
        "print(\"\")\n",
        "print(\"Classification Report for Test Data\")\n",
        "print(\"\")\n",
        "print(classification_report(y_test, y_pred_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "df1850d3",
      "metadata": {
        "id": "df1850d3"
      },
      "source": [
        "Random Forest Classifier Hyperparameter Tuning to find best set of parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8439dbb1",
      "metadata": {
        "id": "8439dbb1"
      },
      "outputs": [],
      "source": [
        "#Hyperparameter Tuning using RandomisedSearch Cross Validation\n",
        "param_grid = {\n",
        "    'n_estimators': [int(x) for x in np.linspace(start=2,stop=100,num=10)],\n",
        "    'max_features': ['auto','sqrt','log2'],\n",
        "    'max_depth': [int(x) for x in np.linspace(10,1000,10)],\n",
        "    'min_samples_split': [2,5,7,10,12,14],\n",
        "    'min_samples_leaf': [1,2,4,6,8],\n",
        "    'criterion': ['entropy','gini']\n",
        "}\n",
        "print(param_grid)\n",
        "rcv = RandomizedSearchCV(estimator=RandomForestClassifier(),param_distributions=param_grid,n_iter=100,cv=5,verbose=2,n_jobs=-1)\n",
        "rcv.fit(X_train,y_train)\n",
        "rcv.best_estimator_"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4e06c196",
      "metadata": {
        "id": "4e06c196"
      },
      "source": [
        "Random Forest Classifier with the best set of parameters "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rcv.best_estimator_"
      ],
      "metadata": {
        "id": "3NjYqMDRBsRT"
      },
      "id": "3NjYqMDRBsRT",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "25aa6387",
      "metadata": {
        "id": "25aa6387"
      },
      "outputs": [],
      "source": [
        "#Train Test split of the entire dataset for training purpose\n",
        "X_train, X_test, y_train, y_test = train_test_split(X ,y , random_state=0,test_size=0.20, shuffle=True)\n",
        "#Model Instatntiated\n",
        "#Model Instatntiated\n",
        "model6 = RandomForestClassifier(criterion='entropy', max_depth=230, max_features='log2',\n",
        "                       min_samples_leaf=4, n_estimators=89)\n",
        "model6.fit(X_train, y_train)\n",
        "#Model Performance Evaluation\n",
        "y_pred_train = model6.predict(X_train)\n",
        "y_pred_test = model6.predict(X_test)\n",
        "\n",
        "#Displaying Confusion Matrix \n",
        "\n",
        "cm_train = confusion_matrix(y_train,y_pred_train )\n",
        "cm_test = confusion_matrix(y_test,y_pred_test )\n",
        "\n",
        "fig, axes = plt.subplots(1, 2,figsize=(15, 5), sharey=True)\n",
        "sns.heatmap(cm_train,annot=True,ax=axes[0])\n",
        "sns.heatmap(cm_test,annot=True,ax=axes[1])\n",
        "axes[0].set_title(\"Confusion Matrix on Train Data\")\n",
        "axes[1].set_title(\"Confusion Matrix on Test Data\")\n",
        "axes[0].set_xlabel('Actual')\n",
        "axes[0].set_ylabel('Predict')\n",
        "axes[1].set_xlabel('Actual')\n",
        "axes[1].set_ylabel('Predict')\n",
        "plt.show()\n",
        "\n",
        "precision_train=precision_score(y_train,y_pred_train,zero_division='warn',average='micro')\n",
        "\n",
        "# model precision for X_train and X_test \n",
        "print( \"Precision on Train Data : \", str(int(precision_train*100)) +'%' )\n",
        "\n",
        "precision_test=precision_score(y_test,y_pred_test,zero_division='warn',average='micro')\n",
        "\n",
        "print( \"Precision on Test Data : \", str(int(precision_test*100)) +'%' ,)\n",
        "\n",
        "recall_train=recall_score(y_train,y_pred_train,zero_division='warn',average='micro')\n",
        "\n",
        "# model recall for X_train and X_test \n",
        "\n",
        "print( \"Recall on Train Data : \", str(int(recall_train*100)) +'%' )\n",
        "\n",
        "recall_test=recall_score(y_test,y_pred_test,zero_division='warn',average='micro')\n",
        "\n",
        "print( \"Recall on Test Data : \", str(int(recall_test*100)) +'%' ,)\n",
        "\n",
        "# model F-1 score for X_train and X_test\n",
        "F1_score_train =f1_score(y_train, y_pred_train,zero_division='warn',average='micro')\n",
        "\n",
        "print( \"F1 on Train Data : \", str(int(F1_score_train*100)) +'%' )\n",
        "\n",
        "F1_score_test =f1_score(y_test, y_pred_test,zero_division='warn',average='micro')\n",
        "\n",
        "print( \"F1 on Test Data : \", str(int(F1_score_test*100)) +'%' )\n",
        "\n",
        "#Displaying Classification Report\n",
        "\n",
        "print(\"\")\n",
        "print(\"Classification Report for Train Data\")\n",
        "print(\"\")\n",
        "print(classification_report(y_train, y_pred_train))\n",
        "print(\"\")\n",
        "print(\"Classification Report for Test Data\")\n",
        "print(\"\")\n",
        "print(classification_report(y_test, y_pred_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "109db35e",
      "metadata": {
        "id": "109db35e"
      },
      "source": [
        "Fitting the data to XGBoost Classifier alongwith model performnace validation using accuracy score, classification report, confusion matrix and R2 score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "86d065c7",
      "metadata": {
        "id": "86d065c7"
      },
      "outputs": [],
      "source": [
        "#Train Test split of the entire dataset for training purpose\n",
        "X_train, X_test, y_train, y_test = train_test_split(X ,y , random_state=0,test_size=0.20, shuffle=True)\n",
        "#Model Instatntiated\n",
        "#Model Instatntiated\n",
        "model7 = XGBClassifier()\n",
        "\n",
        "#Data fit to the model\n",
        "model7.fit(X_train, y_train)\n",
        "\n",
        "model6.fit(X_train, y_train)\n",
        "#Model Performance Evaluation\n",
        "y_pred_train = model7.predict(X_train)\n",
        "y_pred_test = model7.predict(X_test)\n",
        "\n",
        "#Displaying Confusion Matrix \n",
        "\n",
        "cm_train = confusion_matrix(y_train,y_pred_train )\n",
        "cm_test = confusion_matrix(y_test,y_pred_test )\n",
        "\n",
        "fig, axes = plt.subplots(1, 2,figsize=(15, 5), sharey=True)\n",
        "sns.heatmap(cm_train,annot=True,ax=axes[0])\n",
        "sns.heatmap(cm_test,annot=True,ax=axes[1])\n",
        "axes[0].set_title(\"Confusion Matrix on Train Data\")\n",
        "axes[1].set_title(\"Confusion Matrix on Test Data\")\n",
        "axes[0].set_xlabel('Actual')\n",
        "axes[0].set_ylabel('Predict')\n",
        "axes[1].set_xlabel('Actual')\n",
        "axes[1].set_ylabel('Predict')\n",
        "plt.show()\n",
        "\n",
        "precision_train=precision_score(y_train,y_pred_train,zero_division='warn',average='micro')\n",
        "\n",
        "# model precision for X_train and X_test \n",
        "print( \"Precision on Train Data : \", str(int(precision_train*100)) +'%' )\n",
        "\n",
        "precision_test=precision_score(y_test,y_pred_test,zero_division='warn',average='micro')\n",
        "\n",
        "print( \"Precision on Test Data : \", str(int(precision_test*100)) +'%' ,)\n",
        "\n",
        "recall_train=recall_score(y_train,y_pred_train,zero_division='warn',average='micro')\n",
        "\n",
        "# model recall for X_train and X_test \n",
        "\n",
        "print( \"Recall on Train Data : \", str(int(recall_train*100)) +'%' )\n",
        "\n",
        "recall_test=recall_score(y_test,y_pred_test,zero_division='warn',average='micro')\n",
        "\n",
        "print( \"Recall on Test Data : \", str(int(recall_test*100)) +'%' ,)\n",
        "\n",
        "# model F-1 score for X_train and X_test\n",
        "F1_score_train =f1_score(y_train, y_pred_train,zero_division='warn',average='micro')\n",
        "\n",
        "print( \"F1 on Train Data : \", str(int(F1_score_train*100)) +'%' )\n",
        "\n",
        "F1_score_test =f1_score(y_test, y_pred_test,zero_division='warn',average='micro')\n",
        "\n",
        "print( \"F1 on Test Data : \", str(int(F1_score_test*100)) +'%' )\n",
        "\n",
        "#Displaying Classification Report\n",
        "\n",
        "print(\"\")\n",
        "print(\"Classification Report for Train Data\")\n",
        "print(\"\")\n",
        "print(classification_report(y_train, y_pred_train))\n",
        "print(\"\")\n",
        "print(\"Classification Report for Test Data\")\n",
        "print(\"\")\n",
        "print(classification_report(y_test, y_pred_test))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Hyperparameter Tuning using RandomisedSearch Cross Validation\n",
        "param_grid = {\n",
        "    'n_estimators': [int(x) for x in np.linspace(start=2,stop=100,num=10)],\n",
        "    'max_depth': [int(x) for x in np.linspace(10,1000,10)],\n",
        "    'min_samples_split': [2,5,7,10,12,14],\n",
        "    'min_samples_leaf': [1,2,4,6,8],\n",
        "    'criterion': ['entropy','gini'],\n",
        "    'learning_rate': [0.01,0.1,0.2]\n",
        "}\n",
        "print(param_grid)\n",
        "rcv = RandomizedSearchCV(estimator=XGBClassifier(),param_distributions=param_grid,n_iter=100,cv=5,verbose=2,n_jobs=-1)\n",
        "rcv.fit(X_train,y_train)\n",
        "rcv.best_estimator_"
      ],
      "metadata": {
        "id": "5tg-1VAgCo4i"
      },
      "id": "5tg-1VAgCo4i",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Train Test split of the entire dataset for training purpose\n",
        "X_train, X_test, y_train, y_test = train_test_split(X ,y , random_state=0,test_size=0.20, shuffle=True)\n",
        "#Model Instatntiated\n",
        "#Model Instatntiated\n",
        "model8 = XGBClassifier(criterion='gini', max_depth=450, min_samples_leaf=4,\n",
        "              min_samples_split=14, n_estimators=23,\n",
        "              objective='multi:softprob')\n",
        "\n",
        "#Data fit to the model\n",
        "model8.fit(X_train, y_train)\n",
        "\n",
        "model6.fit(X_train, y_train)\n",
        "#Model Performance Evaluation\n",
        "y_pred_train = model8.predict(X_train)\n",
        "y_pred_test = model8.predict(X_test)\n",
        "\n",
        "#Displaying Confusion Matrix \n",
        "\n",
        "cm_train = confusion_matrix(y_train,y_pred_train )\n",
        "cm_test = confusion_matrix(y_test,y_pred_test )\n",
        "\n",
        "fig, axes = plt.subplots(1, 2,figsize=(15, 5), sharey=True)\n",
        "sns.heatmap(cm_train,annot=True,ax=axes[0])\n",
        "sns.heatmap(cm_test,annot=True,ax=axes[1])\n",
        "axes[0].set_title(\"Confusion Matrix on Train Data\")\n",
        "axes[1].set_title(\"Confusion Matrix on Test Data\")\n",
        "axes[0].set_xlabel('Actual')\n",
        "axes[0].set_ylabel('Predict')\n",
        "axes[1].set_xlabel('Actual')\n",
        "axes[1].set_ylabel('Predict')\n",
        "plt.show()\n",
        "\n",
        "precision_train=precision_score(y_train,y_pred_train,zero_division='warn',average='micro')\n",
        "\n",
        "# model precision for X_train and X_test \n",
        "print( \"Precision on Train Data : \", str(int(precision_train*100)) +'%' )\n",
        "\n",
        "precision_test=precision_score(y_test,y_pred_test,zero_division='warn',average='micro')\n",
        "\n",
        "print( \"Precision on Test Data : \", str(int(precision_test*100)) +'%' ,)\n",
        "\n",
        "recall_train=recall_score(y_train,y_pred_train,zero_division='warn',average='micro')\n",
        "\n",
        "# model recall for X_train and X_test \n",
        "\n",
        "print( \"Recall on Train Data : \", str(int(recall_train*100)) +'%' )\n",
        "\n",
        "recall_test=recall_score(y_test,y_pred_test,zero_division='warn',average='micro')\n",
        "\n",
        "print( \"Recall on Test Data : \", str(int(recall_test*100)) +'%' ,)\n",
        "\n",
        "# model F-1 score for X_train and X_test\n",
        "F1_score_train =f1_score(y_train, y_pred_train,zero_division='warn',average='micro')\n",
        "\n",
        "print( \"F1 on Train Data : \", str(int(F1_score_train*100)) +'%' )\n",
        "\n",
        "F1_score_test =f1_score(y_test, y_pred_test,zero_division='warn',average='micro')\n",
        "\n",
        "print( \"F1 on Test Data : \", str(int(F1_score_test*100)) +'%' )\n",
        "\n",
        "#Displaying Classification Report\n",
        "\n",
        "print(\"\")\n",
        "print(\"Classification Report for Train Data\")\n",
        "print(\"\")\n",
        "print(classification_report(y_train, y_pred_train))\n",
        "print(\"\")\n",
        "print(\"Classification Report for Test Data\")\n",
        "print(\"\")\n",
        "print(classification_report(y_test, y_pred_test))"
      ],
      "metadata": {
        "id": "uwuCTU9LDeNq"
      },
      "id": "uwuCTU9LDeNq",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "fa9e7420",
      "metadata": {
        "id": "fa9e7420"
      },
      "source": [
        "The XG Boost Classifier performs the best when it deals with only Continous Features  and inbalance datset with an Train F1-Score of 100% and Test F1-Score of 99% which makes it the best choice of model when trying to predict diabetes using the above mentioned data."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e35d7e85",
      "metadata": {
        "id": "e35d7e85"
      },
      "source": [
        "# Model 2 - All Features"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "09dc71a9",
      "metadata": {
        "id": "09dc71a9"
      },
      "source": [
        "Defining the features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4cc586d9",
      "metadata": {
        "id": "4cc586d9"
      },
      "outputs": [],
      "source": [
        "#Defining the entire dataset with all features\n",
        "X"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a68a6532",
      "metadata": {
        "id": "a68a6532"
      },
      "source": [
        "Splitting the dataset into traning ad test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f1c98fb0",
      "metadata": {
        "id": "f1c98fb0"
      },
      "outputs": [],
      "source": [
        "#Train Test split of the entire dataset for training purpose\n",
        "X_train, X_test, y_train, y_test = train_test_split(X ,y , random_state=0,test_size=0.20, shuffle=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2c1646fc",
      "metadata": {
        "id": "2c1646fc"
      },
      "source": [
        "Fitting the data to Gaussian Naive Bayes Classifier alongwith model performnace validation using accuracy score, classification report, confusion matrix and R2 score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "21042d57",
      "metadata": {
        "id": "21042d57"
      },
      "outputs": [],
      "source": [
        "#Model Instatntiated\n",
        "mod1 = GaussianNB()\n",
        "\n",
        "#Data fit to the model\n",
        "mod1.fit(X_train, y_train)\n",
        "\n",
        "y_pred_train = mod1.predict(X_train)\n",
        "y_pred_test = mod1.predict(X_test)\n",
        "\n",
        "#Displaying Confusion Matrix \n",
        "\n",
        "cm_train = confusion_matrix(y_train,y_pred_train )\n",
        "cm_test = confusion_matrix(y_test,y_pred_test )\n",
        "\n",
        "fig, axes = plt.subplots(1, 2,figsize=(15, 5), sharey=True)\n",
        "sns.heatmap(cm_train,annot=True,ax=axes[0])\n",
        "sns.heatmap(cm_test,annot=True,ax=axes[1])\n",
        "axes[0].set_title(\"Confusion Matrix on Train Data\")\n",
        "axes[1].set_title(\"Confusion Matrix on Test Data\")\n",
        "axes[0].set_xlabel('Actual')\n",
        "axes[0].set_ylabel('Predict')\n",
        "axes[1].set_xlabel('Actual')\n",
        "axes[1].set_ylabel('Predict')\n",
        "plt.show()\n",
        "\n",
        "precision_train=precision_score(y_train,y_pred_train,zero_division='warn',average='micro')\n",
        "\n",
        "# model precision for X_train and X_test \n",
        "print( \"Precision on Train Data : \", str(int(precision_train*100)) +'%' )\n",
        "\n",
        "precision_test=precision_score(y_test,y_pred_test,zero_division='warn',average='micro')\n",
        "\n",
        "print( \"Precision on Test Data : \", str(int(precision_test*100)) +'%' ,)\n",
        "\n",
        "recall_train=recall_score(y_train,y_pred_train,zero_division='warn',average='micro')\n",
        "\n",
        "# model recall for X_train and X_test \n",
        "\n",
        "print( \"Recall on Train Data : \", str(int(recall_train*100)) +'%' )\n",
        "\n",
        "recall_test=recall_score(y_test,y_pred_test,zero_division='warn',average='micro')\n",
        "\n",
        "print( \"Recall on Test Data : \", str(int(recall_test*100)) +'%' ,)\n",
        "\n",
        "# model F-1 score for X_train and X_test\n",
        "F1_score_train =f1_score(y_train, y_pred_train,zero_division='warn',average='micro')\n",
        "\n",
        "print( \"F1 on Train Data : \", str(int(F1_score_train*100)) +'%' )\n",
        "\n",
        "F1_score_test =f1_score(y_test, y_pred_test,zero_division='warn',average='micro')\n",
        "\n",
        "print( \"F1 on Test Data : \", str(int(F1_score_test*100)) +'%' )\n",
        "\n",
        "#Displaying Classification Report\n",
        "\n",
        "print(\"\")\n",
        "print(\"Classification Report for Train Data\")\n",
        "print(\"\")\n",
        "print(classification_report(y_train, y_pred_train))\n",
        "print(\"\")\n",
        "print(\"Classification Report for Test Data\")\n",
        "print(\"\")\n",
        "print(classification_report(y_test, y_pred_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "461d69e8",
      "metadata": {
        "id": "461d69e8"
      },
      "source": [
        "Fitting the data to Logistic Regression Classifier alongwith model performnace validation using accuracy score, classification report, confusion matrix and R2 score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "58269ca0",
      "metadata": {
        "id": "58269ca0"
      },
      "outputs": [],
      "source": [
        "#Model Instatntiated\n",
        "mod2 = LogisticRegression()\n",
        "\n",
        "#Data fit to the model\n",
        "mod2.fit(X_train, y_train)\n",
        "y_pred_train = mod2.predict(X_train)\n",
        "y_pred_test = mod2.predict(X_test)\n",
        "\n",
        "#Displaying Confusion Matrix \n",
        "\n",
        "cm_train = confusion_matrix(y_train,y_pred_train )\n",
        "cm_test = confusion_matrix(y_test,y_pred_test )\n",
        "\n",
        "fig, axes = plt.subplots(1, 2,figsize=(15, 5), sharey=True)\n",
        "sns.heatmap(cm_train,annot=True,ax=axes[0])\n",
        "sns.heatmap(cm_test,annot=True,ax=axes[1])\n",
        "axes[0].set_title(\"Confusion Matrix on Train Data\")\n",
        "axes[1].set_title(\"Confusion Matrix on Test Data\")\n",
        "axes[0].set_xlabel('Actual')\n",
        "axes[0].set_ylabel('Predict')\n",
        "axes[1].set_xlabel('Actual')\n",
        "axes[1].set_ylabel('Predict')\n",
        "plt.show()\n",
        "\n",
        "precision_train=precision_score(y_train,y_pred_train,zero_division='warn',average='micro')\n",
        "\n",
        "# model precision for X_train and X_test \n",
        "print( \"Precision on Train Data : \", str(int(precision_train*100)) +'%' )\n",
        "\n",
        "precision_test=precision_score(y_test,y_pred_test,zero_division='warn',average='micro')\n",
        "\n",
        "print( \"Precision on Test Data : \", str(int(precision_test*100)) +'%' ,)\n",
        "\n",
        "recall_train=recall_score(y_train,y_pred_train,zero_division='warn',average='micro')\n",
        "\n",
        "# model recall for X_train and X_test \n",
        "\n",
        "print( \"Recall on Train Data : \", str(int(recall_train*100)) +'%' )\n",
        "\n",
        "recall_test=recall_score(y_test,y_pred_test,zero_division='warn',average='micro')\n",
        "\n",
        "print( \"Recall on Test Data : \", str(int(recall_test*100)) +'%' ,)\n",
        "\n",
        "# model F-1 score for X_train and X_test\n",
        "F1_score_train =f1_score(y_train, y_pred_train,zero_division='warn',average='micro')\n",
        "\n",
        "print( \"F1 on Train Data : \", str(int(F1_score_train*100)) +'%' )\n",
        "\n",
        "F1_score_test =f1_score(y_test, y_pred_test,zero_division='warn',average='micro')\n",
        "\n",
        "print( \"F1 on Test Data : \", str(int(F1_score_test*100)) +'%' )\n",
        "\n",
        "#Displaying Classification Report\n",
        "\n",
        "print(\"\")\n",
        "print(\"Classification Report for Train Data\")\n",
        "print(\"\")\n",
        "print(classification_report(y_train, y_pred_train))\n",
        "print(\"\")\n",
        "print(\"Classification Report for Test Data\")\n",
        "print(\"\")\n",
        "print(classification_report(y_test, y_pred_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cf84d8a4",
      "metadata": {
        "id": "cf84d8a4"
      },
      "source": [
        "Fitting the data to Support Vector Machine Classifier alongwith model performnace validation using accuracy score, classification report, confusion matrix and R2 score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "464003ce",
      "metadata": {
        "id": "464003ce"
      },
      "outputs": [],
      "source": [
        "#Model Instatntiated\n",
        "mod3 = SVC(kernel='linear',C=1)\n",
        "\n",
        "#Data fit to the model\n",
        "mod3.fit(X_train, y_train)\n",
        "y_pred_train = mod3.predict(X_train)\n",
        "y_pred_test = mod3.predict(X_test)\n",
        "\n",
        "#Displaying Confusion Matrix \n",
        "\n",
        "cm_train = confusion_matrix(y_train,y_pred_train )\n",
        "cm_test = confusion_matrix(y_test,y_pred_test )\n",
        "\n",
        "fig, axes = plt.subplots(1, 2,figsize=(15, 5), sharey=True)\n",
        "sns.heatmap(cm_train,annot=True,ax=axes[0])\n",
        "sns.heatmap(cm_test,annot=True,ax=axes[1])\n",
        "axes[0].set_title(\"Confusion Matrix on Train Data\")\n",
        "axes[1].set_title(\"Confusion Matrix on Test Data\")\n",
        "axes[0].set_xlabel('Actual')\n",
        "axes[0].set_ylabel('Predict')\n",
        "axes[1].set_xlabel('Actual')\n",
        "axes[1].set_ylabel('Predict')\n",
        "plt.show()\n",
        "\n",
        "precision_train=precision_score(y_train,y_pred_train,zero_division='warn',average='micro')\n",
        "\n",
        "# model precision for X_train and X_test \n",
        "print( \"Precision on Train Data : \", str(int(precision_train*100)) +'%' )\n",
        "\n",
        "precision_test=precision_score(y_test,y_pred_test,zero_division='warn',average='micro')\n",
        "\n",
        "print( \"Precision on Test Data : \", str(int(precision_test*100)) +'%' ,)\n",
        "\n",
        "recall_train=recall_score(y_train,y_pred_train,zero_division='warn',average='micro')\n",
        "\n",
        "# model recall for X_train and X_test \n",
        "\n",
        "print( \"Recall on Train Data : \", str(int(recall_train*100)) +'%' )\n",
        "\n",
        "recall_test=recall_score(y_test,y_pred_test,zero_division='warn',average='micro')\n",
        "\n",
        "print( \"Recall on Test Data : \", str(int(recall_test*100)) +'%' ,)\n",
        "\n",
        "# model F-1 score for X_train and X_test\n",
        "F1_score_train =f1_score(y_train, y_pred_train,zero_division='warn',average='micro')\n",
        "\n",
        "print( \"F1 on Train Data : \", str(int(F1_score_train*100)) +'%' )\n",
        "\n",
        "F1_score_test =f1_score(y_test, y_pred_test,zero_division='warn',average='micro')\n",
        "\n",
        "print( \"F1 on Test Data : \", str(int(F1_score_test*100)) +'%' )\n",
        "\n",
        "#Displaying Classification Report\n",
        "\n",
        "print(\"\")\n",
        "print(\"Classification Report for Train Data\")\n",
        "print(\"\")\n",
        "print(classification_report(y_train, y_pred_train))\n",
        "print(\"\")\n",
        "print(\"Classification Report for Test Data\")\n",
        "print(\"\")\n",
        "print(classification_report(y_test, y_pred_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e89ef0bc",
      "metadata": {
        "id": "e89ef0bc"
      },
      "source": [
        "Fitting the data to K Neighbors Classifier with K=3 alongwith model performnace validation using accuracy score, classification report, confusion matrix and R2 score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f8227395",
      "metadata": {
        "id": "f8227395"
      },
      "outputs": [],
      "source": [
        "#Model Instatntiated\n",
        "mod4 = KNeighborsClassifier(n_neighbors=3)\n",
        "\n",
        "#Data fit to the model\n",
        "mod4.fit(X_train, y_train)\n",
        "y_pred_train = mod4.predict(X_train)\n",
        "y_pred_test = mod4.predict(X_test)\n",
        "\n",
        "#Displaying Confusion Matrix \n",
        "\n",
        "cm_train = confusion_matrix(y_train,y_pred_train )\n",
        "cm_test = confusion_matrix(y_test,y_pred_test )\n",
        "\n",
        "fig, axes = plt.subplots(1, 2,figsize=(15, 5), sharey=True)\n",
        "sns.heatmap(cm_train,annot=True,ax=axes[0])\n",
        "sns.heatmap(cm_test,annot=True,ax=axes[1])\n",
        "axes[0].set_title(\"Confusion Matrix on Train Data\")\n",
        "axes[1].set_title(\"Confusion Matrix on Test Data\")\n",
        "axes[0].set_xlabel('Actual')\n",
        "axes[0].set_ylabel('Predict')\n",
        "axes[1].set_xlabel('Actual')\n",
        "axes[1].set_ylabel('Predict')\n",
        "plt.show()\n",
        "\n",
        "precision_train=precision_score(y_train,y_pred_train,zero_division='warn',average='micro')\n",
        "\n",
        "# model precision for X_train and X_test \n",
        "print( \"Precision on Train Data : \", str(int(precision_train*100)) +'%' )\n",
        "\n",
        "precision_test=precision_score(y_test,y_pred_test,zero_division='warn',average='micro')\n",
        "\n",
        "print( \"Precision on Test Data : \", str(int(precision_test*100)) +'%' ,)\n",
        "\n",
        "recall_train=recall_score(y_train,y_pred_train,zero_division='warn',average='micro')\n",
        "\n",
        "# model recall for X_train and X_test \n",
        "\n",
        "print( \"Recall on Train Data : \", str(int(recall_train*100)) +'%' )\n",
        "\n",
        "recall_test=recall_score(y_test,y_pred_test,zero_division='warn',average='micro')\n",
        "\n",
        "print( \"Recall on Test Data : \", str(int(recall_test*100)) +'%' ,)\n",
        "\n",
        "# model F-1 score for X_train and X_test\n",
        "F1_score_train =f1_score(y_train, y_pred_train,zero_division='warn',average='micro')\n",
        "\n",
        "print( \"F1 on Train Data : \", str(int(F1_score_train*100)) +'%' )\n",
        "\n",
        "F1_score_test =f1_score(y_test, y_pred_test,zero_division='warn',average='micro')\n",
        "\n",
        "print( \"F1 on Test Data : \", str(int(F1_score_test*100)) +'%' )\n",
        "\n",
        "#Displaying Classification Report\n",
        "\n",
        "print(\"\")\n",
        "print(\"Classification Report for Train Data\")\n",
        "print(\"\")\n",
        "print(classification_report(y_train, y_pred_train))\n",
        "print(\"\")\n",
        "print(\"Classification Report for Test Data\")\n",
        "print(\"\")\n",
        "print(classification_report(y_test, y_pred_test))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# calculating the accuracy of models with different values of k\n",
        "Train_f_1_score = np.zeros(20)\n",
        "for i in range(1,21):\n",
        "    #Train Model and Predict  \n",
        "    knn = KNeighborsClassifier(n_neighbors = i).fit(X_train,y_train)\n",
        "    yhat= knn.predict(X_train)\n",
        "    Train_f_1_score[i-1] = f1_score(y_train, yhat,average='micro')\n",
        "\n",
        "print(Train_f_1_score)\n",
        "\n",
        "\n",
        "# calculating the accuracy of models with different values of k\n",
        "Test_f_1_score = np.zeros(20)\n",
        "for i in range(1,21):\n",
        "    #Train Model and Predict  \n",
        "    knn = KNeighborsClassifier(n_neighbors = i).fit(X_test,y_test)\n",
        "    yhat= knn.predict(X_test)\n",
        "    Test_f_1_score[i-1] = f1_score(y_test, yhat,average='micro')\n",
        "\n",
        "print(Test_f_1_score)\n",
        "\n",
        "loc = np.arange(1,21,step=1.0)\n",
        "plt.figure(figsize = (10, 6))\n",
        "line1, = plt.plot(range(1,21), Train_f_1_score,label='Train F_1 score')\n",
        "line2, = plt.plot(range(1,21), Test_f_1_score,linestyle = 'dashed',label='Test F_1 score')\n",
        "\n",
        "plt.legend(handles=[line1, line2])\n",
        "plt.xticks(loc)\n",
        "plt.xlabel('Number of Neighbors ')\n",
        "plt.ylabel('F1-Score')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "xgPxwQlJFg5h"
      },
      "id": "xgPxwQlJFg5h",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "When K=3 the F1-score of Train is 0.95 and Test is 0.93 which is the optimal values in the dataset."
      ],
      "metadata": {
        "id": "kcgkcaauGNsP"
      },
      "id": "kcgkcaauGNsP"
    },
    {
      "cell_type": "markdown",
      "id": "7a25d475",
      "metadata": {
        "id": "7a25d475"
      },
      "source": [
        "Fitting the data to Decision Tree Classifier alongwith model performnace validation using accuracy score, classification report, confusion matrix and R2 score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "04a5d544",
      "metadata": {
        "id": "04a5d544"
      },
      "outputs": [],
      "source": [
        "#Model Instatntiated\n",
        "mod5 = DecisionTreeClassifier(random_state=0)\n",
        "\n",
        "#Data fit to the model\n",
        "mod5.fit(X_train, y_train)\n",
        "\n",
        "y_pred_train = mod5.predict(X_train)\n",
        "y_pred_test = mod5.predict(X_test)\n",
        "\n",
        "#Displaying Confusion Matrix \n",
        "\n",
        "cm_train = confusion_matrix(y_train,y_pred_train )\n",
        "cm_test = confusion_matrix(y_test,y_pred_test )\n",
        "\n",
        "fig, axes = plt.subplots(1, 2,figsize=(15, 5), sharey=True)\n",
        "sns.heatmap(cm_train,annot=True,ax=axes[0])\n",
        "sns.heatmap(cm_test,annot=True,ax=axes[1])\n",
        "axes[0].set_title(\"Confusion Matrix on Train Data\")\n",
        "axes[1].set_title(\"Confusion Matrix on Test Data\")\n",
        "axes[0].set_xlabel('Actual')\n",
        "axes[0].set_ylabel('Predict')\n",
        "axes[1].set_xlabel('Actual')\n",
        "axes[1].set_ylabel('Predict')\n",
        "plt.show()\n",
        "\n",
        "precision_train=precision_score(y_train,y_pred_train,zero_division='warn',average='micro')\n",
        "\n",
        "# model precision for X_train and X_test \n",
        "print( \"Precision on Train Data : \", str(int(precision_train*100)) +'%' )\n",
        "\n",
        "precision_test=precision_score(y_test,y_pred_test,zero_division='warn',average='micro')\n",
        "\n",
        "print( \"Precision on Test Data : \", str(int(precision_test*100)) +'%' ,)\n",
        "\n",
        "recall_train=recall_score(y_train,y_pred_train,zero_division='warn',average='micro')\n",
        "\n",
        "# model recall for X_train and X_test \n",
        "\n",
        "print( \"Recall on Train Data : \", str(int(recall_train*100)) +'%' )\n",
        "\n",
        "recall_test=recall_score(y_test,y_pred_test,zero_division='warn',average='micro')\n",
        "\n",
        "print( \"Recall on Test Data : \", str(int(recall_test*100)) +'%' ,)\n",
        "\n",
        "# model F-1 score for X_train and X_test\n",
        "F1_score_train =f1_score(y_train, y_pred_train,zero_division='warn',average='micro')\n",
        "\n",
        "print( \"F1 on Train Data : \", str(int(F1_score_train*100)) +'%' )\n",
        "\n",
        "F1_score_test =f1_score(y_test, y_pred_test,zero_division='warn',average='micro')\n",
        "\n",
        "print( \"F1 on Test Data : \", str(int(F1_score_test*100)) +'%' )\n",
        "\n",
        "#Displaying Classification Report\n",
        "\n",
        "print(\"\")\n",
        "print(\"Classification Report for Train Data\")\n",
        "print(\"\")\n",
        "print(classification_report(y_train, y_pred_train))\n",
        "print(\"\")\n",
        "print(\"Classification Report for Test Data\")\n",
        "print(\"\")\n",
        "print(classification_report(y_test, y_pred_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0331a267",
      "metadata": {
        "id": "0331a267"
      },
      "source": [
        "Fitting the data to Random Forest Classifier alongwith model performnace validation using accuracy score, classification report, confusion matrix and R2 score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6eb89445",
      "metadata": {
        "id": "6eb89445"
      },
      "outputs": [],
      "source": [
        "#Model Instatntiated\n",
        "mod6 = RandomForestClassifier(criterion='entropy',n_estimators=50)\n",
        "mod6 = mod6.fit(X_train,y_train)\n",
        "y_pred_train = mod6.predict(X_train)\n",
        "y_pred_test = mod6.predict(X_test)\n",
        "\n",
        "#Displaying Confusion Matrix \n",
        "\n",
        "cm_train = confusion_matrix(y_train,y_pred_train )\n",
        "cm_test = confusion_matrix(y_test,y_pred_test )\n",
        "\n",
        "fig, axes = plt.subplots(1, 2,figsize=(15, 5), sharey=True)\n",
        "sns.heatmap(cm_train,annot=True,ax=axes[0])\n",
        "sns.heatmap(cm_test,annot=True,ax=axes[1])\n",
        "axes[0].set_title(\"Confusion Matrix on Train Data\")\n",
        "axes[1].set_title(\"Confusion Matrix on Test Data\")\n",
        "axes[0].set_xlabel('Actual')\n",
        "axes[0].set_ylabel('Predict')\n",
        "axes[1].set_xlabel('Actual')\n",
        "axes[1].set_ylabel('Predict')\n",
        "plt.show()\n",
        "\n",
        "precision_train=precision_score(y_train,y_pred_train,zero_division='warn',average='micro')\n",
        "\n",
        "# model precision for X_train and X_test \n",
        "print( \"Precision on Train Data : \", str(int(precision_train*100)) +'%' )\n",
        "\n",
        "precision_test=precision_score(y_test,y_pred_test,zero_division='warn',average='micro')\n",
        "\n",
        "print( \"Precision on Test Data : \", str(int(precision_test*100)) +'%' ,)\n",
        "\n",
        "recall_train=recall_score(y_train,y_pred_train,zero_division='warn',average='micro')\n",
        "\n",
        "# model recall for X_train and X_test \n",
        "\n",
        "print( \"Recall on Train Data : \", str(int(recall_train*100)) +'%' )\n",
        "\n",
        "recall_test=recall_score(y_test,y_pred_test,zero_division='warn',average='micro')\n",
        "\n",
        "print( \"Recall on Test Data : \", str(int(recall_test*100)) +'%' ,)\n",
        "\n",
        "# model F-1 score for X_train and X_test\n",
        "F1_score_train =f1_score(y_train, y_pred_train,zero_division='warn',average='micro')\n",
        "\n",
        "print( \"F1 on Train Data : \", str(int(F1_score_train*100)) +'%' )\n",
        "\n",
        "F1_score_test =f1_score(y_test, y_pred_test,zero_division='warn',average='micro')\n",
        "\n",
        "print( \"F1 on Test Data : \", str(int(F1_score_test*100)) +'%' )\n",
        "\n",
        "#Displaying Classification Report\n",
        "\n",
        "print(\"\")\n",
        "print(\"Classification Report for Train Data\")\n",
        "print(\"\")\n",
        "print(classification_report(y_train, y_pred_train))\n",
        "print(\"\")\n",
        "print(\"Classification Report for Test Data\")\n",
        "print(\"\")\n",
        "print(classification_report(y_test, y_pred_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c85562ac",
      "metadata": {
        "id": "c85562ac"
      },
      "source": [
        "Random Forest Classifier Hyperparameter Tuning to find best set of parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "554e5943",
      "metadata": {
        "id": "554e5943"
      },
      "outputs": [],
      "source": [
        "param_grid = {\n",
        "    'n_estimators': [int(x) for x in np.linspace(start=2,stop=100,num=10)],\n",
        "    'max_features': ['auto','sqrt','log2'],\n",
        "    'max_depth': [int(x) for x in np.linspace(10,1000,10)],\n",
        "    'min_samples_split': [2,5,7,10,12,14],\n",
        "    'min_samples_leaf': [1,2,4,6,8],\n",
        "    'criterion': ['entropy','gini']\n",
        "}\n",
        "print(param_grid)\n",
        "rcv = RandomizedSearchCV(estimator=RandomForestClassifier(),param_distributions=param_grid,n_iter=100,cv=5,verbose=2,n_jobs=-1)\n",
        "rcv.fit(X_train,y_train)\n",
        "rcv.best_estimator_"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rcv.best_estimator_"
      ],
      "metadata": {
        "id": "Uexkve1eHeEV"
      },
      "id": "Uexkve1eHeEV",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "1e6c4c24",
      "metadata": {
        "id": "1e6c4c24"
      },
      "source": [
        "Random Forest Classifier with the best set of parameters "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "189616b4",
      "metadata": {
        "id": "189616b4"
      },
      "outputs": [],
      "source": [
        "#Model Instatntiated\n",
        "mod6 = RandomForestClassifier(max_depth=780, max_features='sqrt', min_samples_split=5,\n",
        "                       n_estimators=23)\n",
        "\n",
        "#Data fit to the model\n",
        "mod6.fit(X_train, y_train)\n",
        "\n",
        "y_pred_train = mod6.predict(X_train)\n",
        "y_pred_test = mod6.predict(X_test)\n",
        "\n",
        "#Displaying Confusion Matrix \n",
        "\n",
        "cm_train = confusion_matrix(y_train,y_pred_train )\n",
        "cm_test = confusion_matrix(y_test,y_pred_test )\n",
        "\n",
        "fig, axes = plt.subplots(1, 2,figsize=(15, 5), sharey=True)\n",
        "sns.heatmap(cm_train,annot=True,ax=axes[0])\n",
        "sns.heatmap(cm_test,annot=True,ax=axes[1])\n",
        "axes[0].set_title(\"Confusion Matrix on Train Data\")\n",
        "axes[1].set_title(\"Confusion Matrix on Test Data\")\n",
        "axes[0].set_xlabel('Actual')\n",
        "axes[0].set_ylabel('Predict')\n",
        "axes[1].set_xlabel('Actual')\n",
        "axes[1].set_ylabel('Predict')\n",
        "plt.show()\n",
        "\n",
        "precision_train=precision_score(y_train,y_pred_train,zero_division='warn',average='micro')\n",
        "\n",
        "# model precision for X_train and X_test \n",
        "print( \"Precision on Train Data : \", str(int(precision_train*100)) +'%' )\n",
        "\n",
        "precision_test=precision_score(y_test,y_pred_test,zero_division='warn',average='micro')\n",
        "\n",
        "print( \"Precision on Test Data : \", str(int(precision_test*100)) +'%' ,)\n",
        "\n",
        "recall_train=recall_score(y_train,y_pred_train,zero_division='warn',average='micro')\n",
        "\n",
        "# model recall for X_train and X_test \n",
        "\n",
        "print( \"Recall on Train Data : \", str(int(recall_train*100)) +'%' )\n",
        "\n",
        "recall_test=recall_score(y_test,y_pred_test,zero_division='warn',average='micro')\n",
        "\n",
        "print( \"Recall on Test Data : \", str(int(recall_test*100)) +'%' ,)\n",
        "\n",
        "# model F-1 score for X_train and X_test\n",
        "F1_score_train =f1_score(y_train, y_pred_train,zero_division='warn',average='micro')\n",
        "\n",
        "print( \"F1 on Train Data : \", str(int(F1_score_train*100)) +'%' )\n",
        "\n",
        "F1_score_test =f1_score(y_test, y_pred_test,zero_division='warn',average='micro')\n",
        "\n",
        "print( \"F1 on Test Data : \", str(int(F1_score_test*100)) +'%' )\n",
        "\n",
        "#Displaying Classification Report\n",
        "\n",
        "print(\"\")\n",
        "print(\"Classification Report for Train Data\")\n",
        "print(\"\")\n",
        "print(classification_report(y_train, y_pred_train))\n",
        "print(\"\")\n",
        "print(\"Classification Report for Test Data\")\n",
        "print(\"\")\n",
        "print(classification_report(y_test, y_pred_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "91b50040",
      "metadata": {
        "id": "91b50040"
      },
      "source": [
        "Fitting the data to XGBoost Classifier alongwith model performnace validation using accuracy score, classification report, confusion matrix and R2 score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "028b7fd0",
      "metadata": {
        "id": "028b7fd0"
      },
      "outputs": [],
      "source": [
        "#Model Instatntiated\n",
        "mod7 = XGBClassifier()\n",
        "\n",
        "\n",
        "#Data fit to the model\n",
        "mod7.fit(X_train, y_train)\n",
        "\n",
        "y_pred_train = mod7.predict(X_train)\n",
        "y_pred_test = mod7.predict(X_test)\n",
        "\n",
        "#Displaying Confusion Matrix \n",
        "\n",
        "cm_train = confusion_matrix(y_train,y_pred_train )\n",
        "cm_test = confusion_matrix(y_test,y_pred_test )\n",
        "\n",
        "fig, axes = plt.subplots(1, 2,figsize=(15, 5), sharey=True)\n",
        "sns.heatmap(cm_train,annot=True,ax=axes[0])\n",
        "sns.heatmap(cm_test,annot=True,ax=axes[1])\n",
        "axes[0].set_title(\"Confusion Matrix on Train Data\")\n",
        "axes[1].set_title(\"Confusion Matrix on Test Data\")\n",
        "axes[0].set_xlabel('Actual')\n",
        "axes[0].set_ylabel('Predict')\n",
        "axes[1].set_xlabel('Actual')\n",
        "axes[1].set_ylabel('Predict')\n",
        "plt.show()\n",
        "\n",
        "precision_train=precision_score(y_train,y_pred_train,zero_division='warn',average='micro')\n",
        "\n",
        "# model precision for X_train and X_test \n",
        "print( \"Precision on Train Data : \", str(int(precision_train*100)) +'%' )\n",
        "\n",
        "precision_test=precision_score(y_test,y_pred_test,zero_division='warn',average='micro')\n",
        "\n",
        "print( \"Precision on Test Data : \", str(int(precision_test*100)) +'%' ,)\n",
        "\n",
        "recall_train=recall_score(y_train,y_pred_train,zero_division='warn',average='micro')\n",
        "\n",
        "# model recall for X_train and X_test \n",
        "\n",
        "print( \"Recall on Train Data : \", str(int(recall_train*100)) +'%' )\n",
        "\n",
        "recall_test=recall_score(y_test,y_pred_test,zero_division='warn',average='micro')\n",
        "\n",
        "print( \"Recall on Test Data : \", str(int(recall_test*100)) +'%' ,)\n",
        "\n",
        "# model F-1 score for X_train and X_test\n",
        "F1_score_train =f1_score(y_train, y_pred_train,zero_division='warn',average='micro')\n",
        "\n",
        "print( \"F1 on Train Data : \", str(int(F1_score_train*100)) +'%' )\n",
        "\n",
        "F1_score_test =f1_score(y_test, y_pred_test,zero_division='warn',average='micro')\n",
        "\n",
        "print( \"F1 on Test Data : \", str(int(F1_score_test*100)) +'%' )\n",
        "\n",
        "#Displaying Classification Report\n",
        "\n",
        "print(\"\")\n",
        "print(\"Classification Report for Train Data\")\n",
        "print(\"\")\n",
        "print(classification_report(y_train, y_pred_train))\n",
        "print(\"\")\n",
        "print(\"Classification Report for Test Data\")\n",
        "print(\"\")\n",
        "print(classification_report(y_test, y_pred_test))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Hyperparameter Tuning using RandomisedSearch Cross Validation\n",
        "param_grid = {\n",
        "    'n_estimators': [int(x) for x in np.linspace(start=2,stop=100,num=10)],\n",
        "    'max_depth': [int(x) for x in np.linspace(10,1000,10)],\n",
        "    'min_samples_split': [2,5,7,10,12,14],\n",
        "    'min_samples_leaf': [1,2,4,6,8],\n",
        "    'criterion': ['entropy','gini'],\n",
        "    'learning_rate': [0.01,0.1,0.2]\n",
        "}\n",
        "print(param_grid)\n",
        "rcv = RandomizedSearchCV(estimator=XGBClassifier(),param_distributions=param_grid,n_iter=100,cv=5,verbose=2,n_jobs=-1)\n",
        "rcv.fit(X_train,y_train)\n",
        "rcv.best_estimator_"
      ],
      "metadata": {
        "id": "DXiEneL3H5Qw"
      },
      "id": "DXiEneL3H5Qw",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mod7 = XGBClassifier(criterion='entropy', max_depth=230, min_samples_leaf=1,\n",
        "              min_samples_split=7, n_estimators=23, objective='multi:softprob')\n",
        "#Data fit to the model\n",
        "mod7.fit(X_train, y_train)\n",
        "\n",
        "y_pred_train = mod7.predict(X_train)\n",
        "y_pred_test = mod7.predict(X_test)\n",
        "\n",
        "#Displaying Confusion Matrix \n",
        "\n",
        "cm_train = confusion_matrix(y_train,y_pred_train )\n",
        "cm_test = confusion_matrix(y_test,y_pred_test )\n",
        "\n",
        "fig, axes = plt.subplots(1, 2,figsize=(15, 5), sharey=True)\n",
        "sns.heatmap(cm_train,annot=True,ax=axes[0])\n",
        "sns.heatmap(cm_test,annot=True,ax=axes[1])\n",
        "axes[0].set_title(\"Confusion Matrix on Train Data\")\n",
        "axes[1].set_title(\"Confusion Matrix on Test Data\")\n",
        "axes[0].set_xlabel('Actual')\n",
        "axes[0].set_ylabel('Predict')\n",
        "axes[1].set_xlabel('Actual')\n",
        "axes[1].set_ylabel('Predict')\n",
        "plt.show()\n",
        "\n",
        "precision_train=precision_score(y_train,y_pred_train,zero_division='warn',average='micro')\n",
        "\n",
        "# model precision for X_train and X_test \n",
        "print( \"Precision on Train Data : \", str(int(precision_train*100)) +'%' )\n",
        "\n",
        "precision_test=precision_score(y_test,y_pred_test,zero_division='warn',average='micro')\n",
        "\n",
        "print( \"Precision on Test Data : \", str(int(precision_test*100)) +'%' ,)\n",
        "\n",
        "recall_train=recall_score(y_train,y_pred_train,zero_division='warn',average='micro')\n",
        "\n",
        "# model recall for X_train and X_test \n",
        "\n",
        "print( \"Recall on Train Data : \", str(int(recall_train*100)) +'%' )\n",
        "\n",
        "recall_test=recall_score(y_test,y_pred_test,zero_division='warn',average='micro')\n",
        "\n",
        "print( \"Recall on Test Data : \", str(int(recall_test*100)) +'%' ,)\n",
        "\n",
        "# model F-1 score for X_train and X_test\n",
        "F1_score_train =f1_score(y_train, y_pred_train,zero_division='warn',average='micro')\n",
        "\n",
        "print( \"F1 on Train Data : \", str(int(F1_score_train*100)) +'%' )\n",
        "\n",
        "F1_score_test =f1_score(y_test, y_pred_test,zero_division='warn',average='micro')\n",
        "\n",
        "print( \"F1 on Test Data : \", str(int(F1_score_test*100)) +'%' )\n",
        "\n",
        "#Displaying Classification Report\n",
        "\n",
        "print(\"\")\n",
        "print(\"Classification Report for Train Data\")\n",
        "print(\"\")\n",
        "print(classification_report(y_train, y_pred_train))\n",
        "print(\"\")\n",
        "print(\"Classification Report for Test Data\")\n",
        "print(\"\")\n",
        "print(classification_report(y_test, y_pred_test))"
      ],
      "metadata": {
        "id": "kY7aXjTAIUMJ"
      },
      "id": "kY7aXjTAIUMJ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "d60d16d3",
      "metadata": {
        "id": "d60d16d3"
      },
      "source": [
        "The XG Boost Classifier performs the best when it deals with All Features with an Train F1 Score of 100%, and Test F1-Score of 99%, which combinedly makes it the best choice of model when trying to predict diabetes using the above mentioned data."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d737100f",
      "metadata": {
        "id": "d737100f"
      },
      "source": [
        "# Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3459406a",
      "metadata": {
        "id": "3459406a"
      },
      "outputs": [],
      "source": [
        "X=df.drop(['BMI'],axis=1)#Declaring Predictors\n",
        "y=df['BMI']#Declaring Target"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9e0aeb0a",
      "metadata": {
        "id": "9e0aeb0a"
      },
      "outputs": [],
      "source": [
        "X"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a4ab0938",
      "metadata": {
        "id": "a4ab0938"
      },
      "source": [
        "# Correlation between variables and output"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "43f40e53",
      "metadata": {
        "id": "43f40e53"
      },
      "source": [
        "We found out the Correlation between the various predictor variables and the output variable or target which is BMI in this case. The higher the values, the more correlated are the two variables."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "311beb10",
      "metadata": {
        "id": "311beb10"
      },
      "source": [
        "Pearsons Correlation Between Gender and BMI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cef77e75",
      "metadata": {
        "id": "cef77e75"
      },
      "outputs": [],
      "source": [
        "cor1,_=pearsonr(X['Gender'],y)\n",
        "cor1"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f7b8b415",
      "metadata": {
        "id": "f7b8b415"
      },
      "source": [
        "Spearman Kendall Correlation Between Gender and BMI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2b324a24",
      "metadata": {
        "id": "2b324a24"
      },
      "outputs": [],
      "source": [
        "cor1,_=kendalltau(X['Gender'],y)\n",
        "cor1"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1b5489d7",
      "metadata": {
        "id": "1b5489d7"
      },
      "source": [
        "Pearsons Correlation Between Age and BMI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2db2084e",
      "metadata": {
        "id": "2db2084e"
      },
      "outputs": [],
      "source": [
        "cor2,_=pearsonr(X['AGE'],y)\n",
        "cor2"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0b0c9ae9",
      "metadata": {
        "id": "0b0c9ae9"
      },
      "source": [
        "Spearman Kendall Correlation Between Age and BMI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3a9a5c09",
      "metadata": {
        "id": "3a9a5c09"
      },
      "outputs": [],
      "source": [
        "cor2,_=kendalltau(X['AGE'],y)\n",
        "cor2"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9e31d8f8",
      "metadata": {
        "id": "9e31d8f8"
      },
      "source": [
        "Pearsons Correlation Between Urea and BMI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f8af6909",
      "metadata": {
        "id": "f8af6909"
      },
      "outputs": [],
      "source": [
        "cor3,_=pearsonr(X['Urea'],y)\n",
        "cor3"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "465091f2",
      "metadata": {
        "id": "465091f2"
      },
      "source": [
        "Spearman Kendall Correlation Between Urea and BMI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6fdd4608",
      "metadata": {
        "id": "6fdd4608"
      },
      "outputs": [],
      "source": [
        "cor3,_=kendalltau(X['Urea'],y)\n",
        "cor3"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3d35a183",
      "metadata": {
        "id": "3d35a183"
      },
      "source": [
        "Pearsons Correlation Between Cr and BMI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7faa9101",
      "metadata": {
        "id": "7faa9101"
      },
      "outputs": [],
      "source": [
        "cor4,_=pearsonr(X['Cr'],y)\n",
        "cor4"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6fca1c4b",
      "metadata": {
        "id": "6fca1c4b"
      },
      "source": [
        "Spearman Kendall Correlation Between Cr and BMI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "adfdd5b0",
      "metadata": {
        "id": "adfdd5b0"
      },
      "outputs": [],
      "source": [
        "cor4,_=kendalltau(X['Cr'],y)\n",
        "cor4"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "acd839a4",
      "metadata": {
        "id": "acd839a4"
      },
      "source": [
        "Pearsons Correlation Between HbA1c and BMI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "46a12f20",
      "metadata": {
        "id": "46a12f20"
      },
      "outputs": [],
      "source": [
        "cor5,_=pearsonr(X['HbA1c'],y)\n",
        "cor5"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fa631ea4",
      "metadata": {
        "id": "fa631ea4"
      },
      "source": [
        "Spearman Kendall Correlation Between HbA1c and BMI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ae2b01a0",
      "metadata": {
        "id": "ae2b01a0"
      },
      "outputs": [],
      "source": [
        "cor5,_=kendalltau(X['HbA1c'],y)\n",
        "cor5"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d14fe68b",
      "metadata": {
        "id": "d14fe68b"
      },
      "source": [
        "Pearsons Correlation Between Chol and BMI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1adfa21c",
      "metadata": {
        "id": "1adfa21c"
      },
      "outputs": [],
      "source": [
        "cor6,_=pearsonr(X['Chol'],y)\n",
        "cor6"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e51a3917",
      "metadata": {
        "id": "e51a3917"
      },
      "source": [
        "Spearman Kendall Correlation Between Chol and BMI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f3e56e87",
      "metadata": {
        "id": "f3e56e87"
      },
      "outputs": [],
      "source": [
        "cor6,_=kendalltau(X['Chol'],y)\n",
        "cor6"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3cb3cf10",
      "metadata": {
        "id": "3cb3cf10"
      },
      "source": [
        "Pearsons Correlation Between TG and BMI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9a6f3b53",
      "metadata": {
        "id": "9a6f3b53"
      },
      "outputs": [],
      "source": [
        "cor7,_=pearsonr(X['TG'],y)\n",
        "cor7"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fb66a113",
      "metadata": {
        "id": "fb66a113"
      },
      "source": [
        "Spearman Kendall Correlation Between TG and BMI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "db32c6c6",
      "metadata": {
        "id": "db32c6c6"
      },
      "outputs": [],
      "source": [
        "cor7,_=kendalltau(X['TG'],y)\n",
        "cor7"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "13d2297f",
      "metadata": {
        "id": "13d2297f"
      },
      "source": [
        "Pearsons Correlation Between HDL and BMI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8e164841",
      "metadata": {
        "id": "8e164841"
      },
      "outputs": [],
      "source": [
        "cor8,_=pearsonr(X['HDL'],y)\n",
        "cor8"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "21f09266",
      "metadata": {
        "id": "21f09266"
      },
      "source": [
        "Spearman Kendall Correlation Between HDL and BMI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eaaea141",
      "metadata": {
        "id": "eaaea141"
      },
      "outputs": [],
      "source": [
        "cor8,_=kendalltau(X['HDL'],y)\n",
        "cor8"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "48ccdc79",
      "metadata": {
        "id": "48ccdc79"
      },
      "source": [
        "Pearsons Correlation Between LDL and BMI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "38ef4578",
      "metadata": {
        "id": "38ef4578"
      },
      "outputs": [],
      "source": [
        "cor9,_=pearsonr(X['LDL'],y)\n",
        "cor9"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ca9233c0",
      "metadata": {
        "id": "ca9233c0"
      },
      "source": [
        "Spearman Kendall Correlation Between LDL and BMI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dde4f6e2",
      "metadata": {
        "id": "dde4f6e2"
      },
      "outputs": [],
      "source": [
        "cor9,_=kendalltau(X['LDL'],y)\n",
        "cor9"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3f60fc5d",
      "metadata": {
        "id": "3f60fc5d"
      },
      "source": [
        "Pearsons Correlation Between VLDL and BMI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "46dc9d17",
      "metadata": {
        "id": "46dc9d17"
      },
      "outputs": [],
      "source": [
        "cor10,_=pearsonr(X['VLDL'],y)\n",
        "cor10"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4e735a10",
      "metadata": {
        "id": "4e735a10"
      },
      "source": [
        "Spearman Kendall Correlation Between VLDL and BMI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e16fe6dc",
      "metadata": {
        "id": "e16fe6dc"
      },
      "outputs": [],
      "source": [
        "cor10,_=kendalltau(X['VLDL'],y)\n",
        "cor10"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c945d8c1",
      "metadata": {
        "id": "c945d8c1"
      },
      "source": [
        "Pearsons Correlation Between CLASS and BMI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "704f824d",
      "metadata": {
        "id": "704f824d"
      },
      "outputs": [],
      "source": [
        "cor11,_=pearsonr(X['CLASS'],y)\n",
        "cor11"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "961cf6ec",
      "metadata": {
        "id": "961cf6ec"
      },
      "source": [
        "Spearman Kendall Correlation Between CLASS and BMI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "831b9cb9",
      "metadata": {
        "id": "831b9cb9"
      },
      "outputs": [],
      "source": [
        "cor11,_=kendalltau(X['CLASS'],y)\n",
        "cor11"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bfb56a3e",
      "metadata": {
        "id": "bfb56a3e"
      },
      "source": [
        "# Linear Regression"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f519ad0f",
      "metadata": {
        "id": "f519ad0f"
      },
      "source": [
        "Linear Regression is a no regularised regression technique. This performs and has a R2 score of 0.39 as per our dataset in deteming BMI based on other features."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "981ed8d9",
      "metadata": {
        "id": "981ed8d9"
      },
      "outputs": [],
      "source": [
        "#Train Test Split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,\n",
        "                                                    random_state=1)\n",
        "  \n",
        "# create linear regression object\n",
        "reg = linear_model.LinearRegression()\n",
        "  \n",
        "# train the model using the training sets\n",
        "reg.fit(X_train, y_train)\n",
        "\n",
        "#Output Prediction\n",
        "y_pred=reg.predict(X_test)\n",
        "  \n",
        "# regression coefficients\n",
        "print('Coefficients: ', reg.coef_)\n",
        "  \n",
        "# variance score: 1 means perfect prediction\n",
        "print('Variance score: {}'.format(reg.score(X_test, y_test)))\n",
        "\n",
        "# R2 Score\n",
        "print('R2 score: {}'.format(r2_score(y_test,y_pred)))\n",
        "\n",
        "# Mean Squared Error\n",
        "print('Mean Squared Error: {}'.format(mean_squared_error(y_test,y_pred)))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "252571cb",
      "metadata": {
        "id": "252571cb"
      },
      "source": [
        "# Lasso Regression"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "73afef0e",
      "metadata": {
        "id": "73afef0e"
      },
      "source": [
        "Lasso Regression is a regularised regression technique. This performs and has a R2 score of 0.40 as per our dataset in deteming BMI based on other features."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "60a32b55",
      "metadata": {
        "id": "60a32b55"
      },
      "outputs": [],
      "source": [
        "#Train Test Split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,\n",
        "                                                    random_state=1)\n",
        "  \n",
        "# create linear regression object\n",
        "reg = linear_model.Lasso(alpha=0.1)\n",
        "  \n",
        "# train the model using the training sets\n",
        "reg.fit(X_train, y_train)\n",
        "\n",
        "#Output Prediction\n",
        "y_pred=reg.predict(X_test)\n",
        "  \n",
        "# regression coefficients\n",
        "print('Coefficients: ', reg.coef_)\n",
        "  \n",
        "# variance score: 1 means perfect prediction\n",
        "print('Variance score: {}'.format(reg.score(X_test, y_test)))\n",
        "\n",
        "# R2 Score\n",
        "print('R2 score: {}'.format(r2_score(y_test,y_pred)))\n",
        "\n",
        "# Mean Squared Error\n",
        "print('Mean Squared Error: {}'.format(mean_squared_error(y_test,y_pred)))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "341bb159",
      "metadata": {
        "id": "341bb159"
      },
      "source": [
        "# Ridge Regression"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7bafccce",
      "metadata": {
        "id": "7bafccce"
      },
      "source": [
        "Ridge Regression is a regularised regression technique. This performs and has a R2 score of 0.39 as per our dataset in deteming BMI based on other features."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b4c07741",
      "metadata": {
        "id": "b4c07741"
      },
      "outputs": [],
      "source": [
        "#Train Test Split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,\n",
        "                                                    random_state=1)\n",
        "  \n",
        "# create linear regression object\n",
        "reg = linear_model.Ridge(alpha=1.0)\n",
        "  \n",
        "# train the model using the training sets\n",
        "reg.fit(X_train, y_train)\n",
        "\n",
        "#Output Prediction\n",
        "y_pred=reg.predict(X_test)\n",
        "  \n",
        "# regression coefficients\n",
        "print('Coefficients: ', reg.coef_)\n",
        "  \n",
        "# variance score: 1 means perfect prediction\n",
        "print('Variance score: {}'.format(reg.score(X_test, y_test)))\n",
        "\n",
        "# R2 Score\n",
        "print('R2 score: {}'.format(r2_score(y_test,y_pred)))\n",
        "\n",
        "# Mean Squared Error\n",
        "print('Mean Squared Error: {}'.format(mean_squared_error(y_test,y_pred)))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2d9a72ed",
      "metadata": {
        "id": "2d9a72ed"
      },
      "source": [
        "# Elastic Net Regression"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3caeca2c",
      "metadata": {
        "id": "3caeca2c"
      },
      "source": [
        "Elastic Net Regression is a regularised regression technique. This performs and has a R2 score of 0.34 as per our dataset in deteming BMI based on other features."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f4420bba",
      "metadata": {
        "id": "f4420bba"
      },
      "outputs": [],
      "source": [
        "#Train Test Split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,\n",
        "                                                    random_state=1)\n",
        "  \n",
        "# create linear regression object\n",
        "reg = linear_model.ElasticNet(random_state=0)\n",
        "  \n",
        "# train the model using the training sets\n",
        "reg.fit(X_train, y_train)\n",
        "\n",
        "#Output Prediction\n",
        "y_pred=reg.predict(X_test)\n",
        "  \n",
        "# regression coefficients\n",
        "print('Coefficients: ', reg.coef_)\n",
        "  \n",
        "# variance score: 1 means perfect prediction\n",
        "print('Variance score: {}'.format(reg.score(X_test, y_test)))\n",
        "\n",
        "# R2 Score\n",
        "print('R2 score: {}'.format(r2_score(y_test,y_pred)))\n",
        "\n",
        "# Mean Squared Error\n",
        "print('Mean Squared Error: {}'.format(mean_squared_error(y_test,y_pred)))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Random Forest Regressor "
      ],
      "metadata": {
        "id": "QsUkRjEClEpk"
      },
      "id": "QsUkRjEClEpk"
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "#Train Test Split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,\n",
        "                                                    random_state=1)\n",
        "  \n",
        "# create linear regression object\n",
        "rf = RandomForestRegressor(n_estimators = 300, max_features = 'sqrt', max_depth = 5, random_state = 18).fit(  X_train, y_train)\n",
        "  \n",
        "# train the model using the training sets\n",
        "rf.fit(X_train, y_train)\n",
        "\n",
        "#Output Prediction\n",
        "y_pred=rf.predict(X_test)\n",
        "\n",
        "# variance score: 1 means perfect prediction\n",
        "print('Variance score: {}'.format(rf.score(X_test, y_test)))\n",
        "\n",
        "# R2 Score\n",
        "print('R2 score: {}'.format(r2_score(y_test,y_pred)))\n",
        "\n",
        "# Mean Squared Error\n",
        "print('Mean Squared Error: {}'.format(mean_squared_error(y_test,y_pred)))"
      ],
      "metadata": {
        "id": "3GUx_L-xlIG6"
      },
      "id": "3GUx_L-xlIG6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import datetime as datetime\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "## Define Grid \n",
        "grid = { \n",
        "    'n_estimators': [200,300,400,500],\n",
        "    'max_features': ['sqrt','log2'],\n",
        "    'max_depth' : [3,4,5,6,7],\n",
        "    'random_state' : [18]\n",
        "}\n",
        "## show start time\n",
        "print(datetime.datetime.now())\n",
        "## Grid Search function\n",
        "CV_rfr = GridSearchCV(estimator=RandomForestRegressor(), param_grid=grid, cv= 5)\n",
        "CV_rfr.fit(X_train, y_train)\n",
        "## show end time\n",
        "print(datetime.datetime.now())"
      ],
      "metadata": {
        "id": "eqBJWaJHnDSf"
      },
      "id": "eqBJWaJHnDSf",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "CV_rfr.best_estimator_"
      ],
      "metadata": {
        "id": "-V2MW66zrYzC"
      },
      "id": "-V2MW66zrYzC",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create linear regression object\n",
        "rf = RandomForestRegressor(max_depth=7, max_features='sqrt', n_estimators=500,\n",
        "                      random_state=18).fit(  X_train, y_train)\n",
        "  \n",
        "# train the model using the training sets\n",
        "rf.fit(X_train, y_train)\n",
        "\n",
        "#Output Prediction\n",
        "y_pred=rf.predict(X_test)\n",
        "\n",
        "# variance score: 1 means perfect prediction\n",
        "print('Variance score: {}'.format(rf.score(X_test, y_test)))\n",
        "\n",
        "# R2 Score\n",
        "print('R2 score: {}'.format(r2_score(y_test,y_pred)))\n",
        "\n",
        "# Mean Squared Error\n",
        "print('Mean Squared Error: {}'.format(mean_squared_error(y_test,y_pred)))"
      ],
      "metadata": {
        "id": "tatSwDhBuJQH"
      },
      "id": "tatSwDhBuJQH",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Gradient Boosting Regressor**"
      ],
      "metadata": {
        "id": "ewJ7BkuEulQo"
      },
      "id": "ewJ7BkuEulQo"
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "\n",
        "#Train Test Split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,\n",
        "                                                    random_state=1)\n",
        "  \n",
        "# train the model using the training sets\n",
        "gbr = GradientBoostingRegressor().fit(X_train,y_train)\n",
        "\n",
        "#Output Prediction\n",
        "y_pred=gbr.predict(X_test)\n",
        "\n",
        "# variance score: 1 means perfect prediction\n",
        "print('Variance score: {}'.format(gbr.score(X_test, y_test)))\n",
        "\n",
        "# R2 Score\n",
        "print('R2 score: {}'.format(r2_score(y_test,y_pred)))\n",
        "\n",
        "# Mean Squared Error\n",
        "print('Mean Squared Error: {}'.format(mean_squared_error(y_test,y_pred)))\n",
        "\n"
      ],
      "metadata": {
        "id": "FFlYdBo9uWS-"
      },
      "id": "FFlYdBo9uWS-",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "param_grid = {'n_estimators':[200,300,400,500],\n",
        "              'max_depth':[3,4,5,6,7], #range(5,16,2), \n",
        "              'min_samples_split':[50,100], #range(200,1001,200), \n",
        "              'learning_rate':[0.01,0.1,0.2],\n",
        "              'random_state' : [18]}\n",
        "\n",
        "## show start time\n",
        "print(datetime.datetime.now())\n",
        "## Grid Search function\n",
        "CV_rfr = GridSearchCV(estimator=GradientBoostingRegressor(), param_grid=param_grid, cv= 5)\n",
        "CV_rfr.fit(X_train, y_train)\n",
        "## show end time\n",
        "print(datetime.datetime.now())"
      ],
      "metadata": {
        "id": "x_GbrwhAwXok"
      },
      "id": "x_GbrwhAwXok",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "CV_rfr.best_estimator_"
      ],
      "metadata": {
        "id": "om3kjxV3zddJ"
      },
      "id": "om3kjxV3zddJ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Train Test Split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,\n",
        "                                                    random_state=1)\n",
        "# train the model using the training sets\n",
        "gbr = GradientBoostingRegressor(learning_rate=0.01, max_depth=7, min_samples_split=50,\n",
        "                          n_estimators=500, random_state=18).fit(X_train,y_train)\n",
        "\n",
        "#Output Prediction\n",
        "y_pred=gbr.predict(X_test)\n",
        "\n",
        "# variance score: 1 means perfect prediction\n",
        "print('Variance score: {}'.format(gbr.score(X_test, y_test)))\n",
        "\n",
        "# R2 Score\n",
        "print('R2 score: {}'.format(r2_score(y_test,y_pred)))\n",
        "\n",
        "# Mean Squared Error\n",
        "print('Mean Squared Error: {}'.format(mean_squared_error(y_test,y_pred)))"
      ],
      "metadata": {
        "id": "VgvESx_Kzioc"
      },
      "id": "VgvESx_Kzioc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "e252a64d",
      "metadata": {
        "id": "e252a64d"
      },
      "source": [
        "# Perfomance Validation"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4406f9c4",
      "metadata": {
        "id": "4406f9c4"
      },
      "source": [
        "So as per the experimentation Lasso Regression performs the best on our given dataset with an R2 score of 0.40 which is the highest among other models. Also it has a mean squared error of 13.98 which says it has the lowest error and confirms that this performs the best."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "private_outputs": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}